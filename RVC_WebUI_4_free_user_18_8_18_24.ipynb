{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cRMphhqG-C5"
   },
   "source": [
    "<h1><center> Retrieval based Voice Conversion WebUI Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFFCx5J80SGa"
   },
   "source": [
    "vist original colab here -> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jwu07JgqoFON"
   },
   "outputs": [],
   "source": [
    "# @title mount drive (optional)\n",
    "\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets antlr4-python3-runtime==4.9.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/antlr4-go/antlr.git\n",
    "# !pip install ipywidgets antlr4-python3-runtime==4.9.3 scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a12f6952c4d46f3a04608ffbeb45311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='‚úî Success', style=ButtonStyle())"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title install (Windows compatible)\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Button\n",
    "import subprocess, shlex, os, sys\n",
    "\n",
    "var = \"WebUI\"\n",
    "test = \"Voice\"\n",
    "c_word = \"Conversion\"\n",
    "r_word = \"Retrieval\"\n",
    "\n",
    "repo_url = f\"https://github.com/RVC-Project/{r_word}-based-{test}-{c_word}-{var}\"\n",
    "repo_dir = os.path.join(os.getcwd(), \"RVC_\")\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir])\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "pretrains = [\"f0D32k.pth\", \"f0G32k.pth\"]\n",
    "new_pretrains = [\"f0Ov2Super32kD.pth\", \"f0Ov2Super32kG.pth\"]\n",
    "\n",
    "pretrain_dir = os.path.join(repo_dir, \"assets\", \"pretrained_v2\")\n",
    "os.makedirs(pretrain_dir, exist_ok=True)\n",
    "\n",
    "def download_file(url, output_path):\n",
    "    if sys.platform == \"win32\":\n",
    "        # Use curl for Windows\n",
    "        cmd = f'curl -L \"{url}\" -o \"{output_path}\"'\n",
    "    else:\n",
    "        # Use aria2c for Linux\n",
    "        cmd = f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}\" -d \"{os.path.dirname(output_path)}\" -o \"{os.path.basename(output_path)}\"'\n",
    "    try:\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "for file in pretrains:\n",
    "    dest = os.path.join(pretrain_dir, file)\n",
    "    if not os.path.exists(dest):\n",
    "        url = f\"https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/{file}\"\n",
    "        download_file(url, dest)\n",
    "\n",
    "for file in new_pretrains:\n",
    "    dest = os.path.join(pretrain_dir, file)\n",
    "    if not os.path.exists(dest):\n",
    "        url = f\"https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/{file}\"\n",
    "        download_file(url, dest)\n",
    "\n",
    "# Install dependencies\n",
    "if sys.platform == \"win32\":\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pip==23.3.1\"])\n",
    "    subprocess.run([\"git\", \"pull\"])\n",
    "    subprocess.run([\"curl\", \"-L\", \"https://huggingface.co/Rejekts/project/resolve/main/download_files.py\", \"-o\", os.path.join(repo_dir, \"download_files.py\")])\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"yt_dlp\"])\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pytube\", \"pydub\", \"gradio==3.42.0\"])\n",
    "    subprocess.run([sys.executable, \"download_files.py\"])\n",
    "    subprocess.run([sys.executable, \"tools/download_models.py\"])\n",
    "else:\n",
    "    !pip install pip==23.3.1\n",
    "    !git pull\n",
    "    !wget -nc https://huggingface.co/Rejekts/project/resolve/main/download_files.py -O ./download_files.py\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install yt_dlp\n",
    "    !pip install pytube pydub gradio==3.42.0\n",
    "    !python ./download_files.py\n",
    "    !python ./tools/download_models.py\n",
    "\n",
    "clear_output()\n",
    "Button(description=\"\\u2714 Success\", button_style=\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWwACtu5KZzV"
   },
   "source": [
    "# Training No UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertido: Audio 1.mp3 -> Audio 1.wav\n",
      "Convertido: Audio 10.mp3 -> Audio 10.wav\n",
      "Convertido: Audio 11.mp3 -> Audio 11.wav\n",
      "Convertido: Audio 12.mp3 -> Audio 12.wav\n",
      "Convertido: Audio 13.mp3 -> Audio 13.wav\n",
      "Convertido: Audio 11.mp3 -> Audio 11.wav\n",
      "Convertido: Audio 12.mp3 -> Audio 12.wav\n",
      "Convertido: Audio 13.mp3 -> Audio 13.wav\n",
      "Convertido: Audio 14.mp3 -> Audio 14.wav\n",
      "Convertido: Audio 15.mp3 -> Audio 15.wav\n",
      "Convertido: Audio 16.mp3 -> Audio 16.wav\n",
      "Convertido: Audio 14.mp3 -> Audio 14.wav\n",
      "Convertido: Audio 15.mp3 -> Audio 15.wav\n",
      "Convertido: Audio 16.mp3 -> Audio 16.wav\n",
      "Convertido: Audio 17.mp3 -> Audio 17.wav\n",
      "Convertido: Audio 18.mp3 -> Audio 18.wav\n",
      "Convertido: Audio 19.mp3 -> Audio 19.wav\n",
      "Convertido: Audio 17.mp3 -> Audio 17.wav\n",
      "Convertido: Audio 18.mp3 -> Audio 18.wav\n",
      "Convertido: Audio 19.mp3 -> Audio 19.wav\n",
      "Convertido: Audio 2.mp3 -> Audio 2.wav\n",
      "Convertido: Audio 20.mp3 -> Audio 20.wav\n",
      "Convertido: Audio 2.mp3 -> Audio 2.wav\n",
      "Convertido: Audio 20.mp3 -> Audio 20.wav\n",
      "Convertido: Audio 3.mp3 -> Audio 3.wav\n",
      "Convertido: Audio 4.mp3 -> Audio 4.wav\n",
      "Convertido: Audio 3.mp3 -> Audio 3.wav\n",
      "Convertido: Audio 4.mp3 -> Audio 4.wav\n",
      "Convertido: Audio 5.mp3 -> Audio 5.wav\n",
      "Convertido: Audio 6.mp3 -> Audio 6.wav\n",
      "Convertido: Audio 5.mp3 -> Audio 5.wav\n",
      "Convertido: Audio 6.mp3 -> Audio 6.wav\n",
      "Convertido: Audio 7.mp3 -> Audio 7.wav\n",
      "Convertido: Audio 8.mp3 -> Audio 8.wav\n",
      "Convertido: Audio 7.mp3 -> Audio 7.wav\n",
      "Convertido: Audio 8.mp3 -> Audio 8.wav\n",
      "Convertido: Audio 9.mp3 -> Audio 9.wav\n",
      "Convertido: Audio 9.mp3 -> Audio 9.wav\n"
     ]
    }
   ],
   "source": [
    "# Convert to wav\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "from pydub.utils import which\n",
    "\n",
    "# Configurar FFmpeg\n",
    "AudioSegment.converter = which(\"ffmpeg\")\n",
    "\n",
    "input_folder = r'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset'\n",
    "output_folder = r'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset_wav'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith('.mp3'):\n",
    "        mp3_path = f\"{input_folder}/{filename}\"\n",
    "        wav_filename = os.path.splitext(filename)[0] + '.wav'\n",
    "        wav_path = f\"{output_folder}/{wav_filename}\"\n",
    "        try:\n",
    "            audio = AudioSegment.from_mp3(mp3_path)\n",
    "            audio.export(wav_path, format='wav')\n",
    "            print(f'Convertido: {filename} -> {wav_filename}')\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error: FFmpeg no est√° instalado o no est√° en el PATH del sistema.')\n",
    "        except Exception as e:\n",
    "            print(f'Error con {filename}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ RVC Path: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect\\RVC\n",
      "üìÇ Directorio original: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\n",
      "üìÇ Cambiado a directorio RVC: C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\n",
      "üì• Importando funci√≥n de preprocesamiento...\n",
      "‚úÖ Funci√≥n preprocess_trainset importada exitosamente\n",
      "\n",
      "üìã CONFIGURACI√ìN DE PREPROCESAMIENTO:\n",
      "   ‚Ä¢ Dataset de entrada: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset_wav\n",
      "   ‚Ä¢ Modelo: My-Voice\n",
      "   ‚Ä¢ Sample rate: 32000 Hz\n",
      "   ‚Ä¢ Hilos de procesamiento: 2\n",
      "   ‚Ä¢ Directorio de salida: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect/RVC/logs/My-Voice\n",
      "   ‚Ä¢ Uso de F0: False\n",
      "   ‚Ä¢ Umbral F0: 3.0\n",
      "‚úÖ Dataset encontrado: 20 archivos WAV\n",
      "   Primeros archivos: ['Audio 1.wav', 'Audio 10.wav', 'Audio 11.wav']\n",
      "\n",
      "üöÄ Iniciando preprocesamiento del dataset...\n",
      "Este proceso puede tardar varios minutos dependiendo del tama√±o del dataset\n",
      "start preprocess\n",
      "end preprocess\n",
      "\n",
      "‚úÖ PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\n",
      "üìÅ Archivos generados en: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect/RVC/logs/My-Voice\n",
      "üìÇ Subdirectorios creados: ['0_gt_wavs', '1_16k_wavs', '2a_f0', '2b-f0nsf', '3_feature768']\n",
      "   ‚Ä¢ 0_gt_wavs: 331 archivos\n",
      "   ‚Ä¢ 1_16k_wavs: 331 archivos\n",
      "   ‚Ä¢ 2a_f0: 331 archivos\n",
      "   ‚Ä¢ 2b-f0nsf: 331 archivos\n",
      "   ‚Ä¢ 3_feature768: 331 archivos\n",
      "\n",
      "üìÇ Restaurado al directorio original: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\n",
      "end preprocess\n",
      "\n",
      "‚úÖ PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\n",
      "üìÅ Archivos generados en: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect/RVC/logs/My-Voice\n",
      "üìÇ Subdirectorios creados: ['0_gt_wavs', '1_16k_wavs', '2a_f0', '2b-f0nsf', '3_feature768']\n",
      "   ‚Ä¢ 0_gt_wavs: 331 archivos\n",
      "   ‚Ä¢ 1_16k_wavs: 331 archivos\n",
      "   ‚Ä¢ 2a_f0: 331 archivos\n",
      "   ‚Ä¢ 2b-f0nsf: 331 archivos\n",
      "   ‚Ä¢ 3_feature768: 331 archivos\n",
      "\n",
      "üìÇ Restaurado al directorio original: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üîß PREPROCESAMIENTO DEL DATASET / DATASET PREPROCESSING\n",
    "# =============================================================================\n",
    "# Esta celda prepara el dataset de audio para el entrenamiento RVC\n",
    "# Incluye configuraci√≥n de paths, normalizaci√≥n de audio y extracci√≥n inicial\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# =============================================================================\n",
    "# üìÅ CONFIGURACI√ìN DE RUTAS Y PATHS / PATH CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Configurar rutas principales del proyecto\n",
    "curr_path = 'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect'\n",
    "dataset_folder = 'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset_wav'\n",
    "model_name = 'My-Voice'\n",
    "\n",
    "# Configurar path de RVC para importaciones\n",
    "rvc_path = os.path.join(curr_path, 'RVC')\n",
    "print(f\"üìÇ RVC Path: {rvc_path}\")\n",
    "\n",
    "# Agregar RVC al Python path si no est√° ya\n",
    "if rvc_path not in sys.path:\n",
    "    sys.path.insert(0, rvc_path)\n",
    "    print(\"‚úÖ RVC path agregado al sistema\")\n",
    "\n",
    "# Cambiar al directorio RVC para imports relativos\n",
    "original_cwd = os.getcwd()\n",
    "print(f\"üìÇ Directorio original: {original_cwd}\")\n",
    "\n",
    "try:\n",
    "    os.chdir(rvc_path)\n",
    "    print(f\"üìÇ Cambiado a directorio RVC: {os.getcwd()}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # üì¶ IMPORTACI√ìN DE M√ìDULOS RVC / RVC MODULES IMPORT\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Ahora importar la funci√≥n de preprocesamiento\n",
    "    print(\"üì• Importando funci√≥n de preprocesamiento...\")\n",
    "    from infer.modules.train.preprocess import preprocess_trainset\n",
    "    print(\"‚úÖ Funci√≥n preprocess_trainset importada exitosamente\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ‚öôÔ∏è CONFIGURACI√ìN DE PAR√ÅMETROS / PARAMETER CONFIGURATION\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Par√°metros del preprocesamiento\n",
    "    sample_rate = 32000      # Frecuencia de muestreo (32kHz recomendado)\n",
    "    num_threads = 2          # N√∫mero de hilos para procesamiento paralelo\n",
    "    log_path = f'{curr_path}/RVC/logs/{model_name}'  # Ruta de logs del experimento\n",
    "    use_f0 = False          # Configuraci√≥n F0 (False = no usar paralelizaci√≥n)\n",
    "    f0_threshold = 3.0      # Umbral de pitch (valor por defecto)\n",
    "    \n",
    "    # Mostrar configuraci√≥n\n",
    "    print(f\"\\nüìã CONFIGURACI√ìN DE PREPROCESAMIENTO:\")\n",
    "    print(f\"   ‚Ä¢ Dataset de entrada: {dataset_folder}\")\n",
    "    print(f\"   ‚Ä¢ Modelo: {model_name}\")\n",
    "    print(f\"   ‚Ä¢ Sample rate: {sample_rate} Hz\")\n",
    "    print(f\"   ‚Ä¢ Hilos de procesamiento: {num_threads}\")\n",
    "    print(f\"   ‚Ä¢ Directorio de salida: {log_path}\")\n",
    "    print(f\"   ‚Ä¢ Uso de F0: {use_f0}\")\n",
    "    print(f\"   ‚Ä¢ Umbral F0: {f0_threshold}\")\n",
    "    \n",
    "    # Verificar que existe el dataset\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        print(f\"‚ùå ERROR: No se encuentra el dataset en {dataset_folder}\")\n",
    "        print(\"   Aseg√∫rate de haber ejecutado la celda de conversi√≥n MP3 a WAV primero\")\n",
    "    else:\n",
    "        wav_files = [f for f in os.listdir(dataset_folder) if f.lower().endswith('.wav')]\n",
    "        print(f\"‚úÖ Dataset encontrado: {len(wav_files)} archivos WAV\")\n",
    "        \n",
    "        if len(wav_files) == 0:\n",
    "            print(\"‚ö†Ô∏è  ADVERTENCIA: No se encontraron archivos WAV en el dataset\")\n",
    "        else:\n",
    "            print(f\"   Primeros archivos: {wav_files[:3]}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # üöÄ EJECUCI√ìN DEL PREPROCESAMIENTO / PREPROCESSING EXECUTION\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\nüöÄ Iniciando preprocesamiento del dataset...\")\n",
    "    print(\"Este proceso puede tardar varios minutos dependiendo del tama√±o del dataset\")\n",
    "    \n",
    "    # Ejecutar la funci√≥n preprocess_trainset\n",
    "    try:\n",
    "        preprocess_trainset(\n",
    "            inp_root=dataset_folder,     # Directorio de entrada con archivos WAV\n",
    "            sr=sample_rate,              # Sample rate\n",
    "            n_p=num_threads,             # N√∫mero de procesos paralelos\n",
    "            exp_dir=log_path,            # Directorio de experimento (salida)\n",
    "            per=f0_threshold,            # Percentil para F0\n",
    "            noparallel=use_f0            # Si usar paralelizaci√≥n (False = s√≠ usar)\n",
    "        )\n",
    "        print(\"\\n‚úÖ PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\")\n",
    "        print(f\"üìÅ Archivos generados en: {log_path}\")\n",
    "        \n",
    "        # Verificar archivos generados\n",
    "        if os.path.exists(log_path):\n",
    "            subdirs = [d for d in os.listdir(log_path) if os.path.isdir(os.path.join(log_path, d))]\n",
    "            print(f\"üìÇ Subdirectorios creados: {subdirs}\")\n",
    "            \n",
    "            # Verificar contenido de cada subdirectorio\n",
    "            for subdir in subdirs:\n",
    "                subdir_path = os.path.join(log_path, subdir)\n",
    "                files_count = len([f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))])\n",
    "                print(f\"   ‚Ä¢ {subdir}: {files_count} archivos\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Directorio de salida no encontrado, pero proceso complet√≥ sin errores\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR DURANTE EL PREPROCESAMIENTO:\")\n",
    "        print(f\"   Tipo de error: {type(e).__name__}\")\n",
    "        print(f\"   Mensaje: {str(e)}\")\n",
    "        # Mostrar traceback completo para debugging\n",
    "        import traceback\n",
    "        print(f\"\\nüîç TRACEBACK COMPLETO:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Restaurar directorio original\n",
    "    os.chdir(original_cwd)\n",
    "    print(f\"\\nüìÇ Restaurado al directorio original: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Extracci√≥n F0 y caracter√≠sticas completada exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Verificar dependencias antes de continuar\n",
    "# Add RVC to Python path\n",
    "rvc_path = os.path.join(curr_path, 'RVC')\n",
    "if rvc_path not in sys.path:\n",
    "    sys.path.append(rvc_path)\n",
    "\n",
    "# Change to RVC directory for relative paths\n",
    "original_cwd = os.getcwd()\n",
    "os.chdir(rvc_path)\n",
    "\n",
    "try:\n",
    "    # Import the modified extraction functions\n",
    "    print(\"\\nImportando funciones de extracci√≥n...\")\n",
    "    from infer.modules.train.extract.extract_f0_print import extract_f0_print\n",
    "    \n",
    "    # Intentar importar fairseq, si falla usar solo F0\n",
    "    try:\n",
    "        from infer.modules.train.extract_feature_print import extract_feature_print\n",
    "        fairseq_available = True\n",
    "        print(\"‚úì Funciones de extracci√≥n HuBERT disponibles\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Error importando HuBERT: {e}\")\n",
    "        print(\"Continuando solo con extracci√≥n F0...\")\n",
    "        fairseq_available = False\n",
    "    \n",
    "    f0method = \"pm\"  # Options: [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
    "    exp_dir_path = f\"./logs/{model_name}\"\n",
    "    \n",
    "    print(f\"\\nIniciando extracci√≥n usando funciones Python puras...\")\n",
    "    \n",
    "    # Extract F0 features (esto siempre deber√≠a funcionar)\n",
    "    print(\"Paso 1: Extrayendo caracter√≠sticas F0...\")\n",
    "    f0_success = extract_f0_print(\n",
    "        exp_dir=exp_dir_path,\n",
    "        n_p=2,  # Number of processes\n",
    "        f0method=f0method\n",
    "    )\n",
    "    \n",
    "    if f0_success:\n",
    "        print(\"‚úì Extracci√≥n F0 completada exitosamente!\")\n",
    "        \n",
    "        # Extract HuBERT features (solo si fairseq est√° disponible)\n",
    "        if fairseq_available:\n",
    "            print(\"Paso 2: Extrayendo caracter√≠sticas HuBERT...\")\n",
    "            try:\n",
    "                feature_success = extract_feature_print(\n",
    "                    device_arg=\"cuda:0\",\n",
    "                    n_part=1,\n",
    "                    i_part=0,\n",
    "                    exp_dir=exp_dir_path,\n",
    "                    version=\"v2\",\n",
    "                    is_half=True\n",
    "                )\n",
    "                \n",
    "                if feature_success:\n",
    "                    print(\"‚úì Extracci√≥n HuBERT completada exitosamente!\")\n",
    "                    \n",
    "                    # Check completion\n",
    "                    log_file_path = f'{exp_dir_path}/extract_f0_feature.log'\n",
    "                    try:\n",
    "                        with open(log_file_path, 'r') as f:\n",
    "                            log_content = f.read()\n",
    "                            if 'all-feature-done' in log_content:\n",
    "                                clear_output()\n",
    "                                print(\"‚úì Extracci√≥n F0 y caracter√≠sticas completada exitosamente!\")\n",
    "                            else:\n",
    "                                print(\"Proceso completado pero marcador 'all-feature-done' no encontrado\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(\"Advertencia: Archivo de log no encontrado, pero extracci√≥n aparenta ser exitosa\")\n",
    "                else:\n",
    "                    print(\"‚ùå Extracci√≥n HuBERT fall√≥\")\n",
    "            except Exception as feature_error:\n",
    "                print(f\"‚ùå Error en extracci√≥n HuBERT: {feature_error}\")\n",
    "                print(\"Continuando solo con F0...\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Saltando extracci√≥n HuBERT (fairseq no disponible)\")\n",
    "            print(\"Solo se complet√≥ la extracci√≥n F0. Para entrenamiento completo, resuelve los problemas de fairseq.\")\n",
    "    else:\n",
    "        print(\"‚ùå Extracci√≥n F0 fall√≥\")\n",
    "        \n",
    "except ImportError as import_error:\n",
    "    print(f\"‚ùå Error de importaci√≥n: {import_error}\")\n",
    "    print(\"Algunas dependencias requeridas a√∫n faltan.\")\n",
    "    print(\"Ejecuta la celda anterior para instalar dependencias.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error durante extracci√≥n F0 y caracter√≠sticas: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Restore original working directory\n",
    "    os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "gSXD8O5aK79w"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fdbbb89f9d497d9541153664a29aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='‚úÖ √çndice Completado', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ √çNDICE COMPLETADO:\n",
      "üìÅ Archivo: logs/My-Voice/added_IVF1264_Flat_nprobe_1_My-Voice_v2.index\n",
      "üìä Vectores: 49319\n",
      "üîç Clusters IVF: 1264\n",
      "üìê Dimensiones: 768\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import traceback\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import Button\n",
    "\n",
    "from RVC.configs import config\n",
    "\n",
    "os.chdir(curr_path + '/RVC')\n",
    "\n",
    "def train_index(exp_dir1, version19):\n",
    "    \"\"\"\n",
    "    Construye un √≠ndice FAISS para b√∫squeda r√°pida de caracter√≠sticas durante la inferencia.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir1: Nombre del experimento/modelo\n",
    "        version19: Versi√≥n del modelo (\"v1\" o \"v2\")\n",
    "    \n",
    "    Returns:\n",
    "        Generator que yield mensajes de progreso\n",
    "    \"\"\"\n",
    "    # Configurar directorios\n",
    "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Seleccionar directorio de caracter√≠sticas seg√∫n la versi√≥n\n",
    "    # v1 usa caracter√≠sticas de 256 dimensiones, v2 usa 768 dimensiones\n",
    "    feature_dir = (\n",
    "        \"%s/3_feature256\" % (exp_dir)\n",
    "        if version19 == \"v1\"\n",
    "        else \"%s/3_feature768\" % (exp_dir)\n",
    "    )\n",
    "    \n",
    "    # Verificar que existan las caracter√≠sticas extra√≠das\n",
    "    if not os.path.exists(feature_dir):\n",
    "        return \"¬°Por favor, realiza primero la extracci√≥n de caracter√≠sticas!\"\n",
    "    \n",
    "    listdir_res = list(os.listdir(feature_dir))\n",
    "    if len(listdir_res) == 0:\n",
    "        return \"¬°Por favor, realiza primero la extracci√≥n de caracter√≠sticas!\"\n",
    "    \n",
    "    infos = []  # Lista para almacenar mensajes de progreso\n",
    "    npys = []   # Lista para almacenar vectores de caracter√≠sticas\n",
    "    \n",
    "    # Cargar todos los archivos .npy de caracter√≠sticas\n",
    "    print(f\"Cargando {len(listdir_res)} archivos de caracter√≠sticas...\")\n",
    "    for name in sorted(listdir_res):\n",
    "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
    "        npys.append(phone)\n",
    "    \n",
    "    # Concatenar todas las caracter√≠sticas en un solo array\n",
    "    big_npy = np.concatenate(npys, 0)\n",
    "    print(f\"Caracter√≠sticas totales: {big_npy.shape}\")\n",
    "    \n",
    "    # Mezclar aleatoriamente las caracter√≠sticas para mejor distribuci√≥n\n",
    "    big_npy_idx = np.arange(big_npy.shape[0])\n",
    "    np.random.shuffle(big_npy_idx)\n",
    "    big_npy = big_npy[big_npy_idx]\n",
    "    \n",
    "    # Si hay m√°s de 200k vectores, aplicar K-means para reducir a 10k centros\n",
    "    # Esto reduce el tama√±o del √≠ndice y mejora la velocidad de b√∫squeda\n",
    "    if big_npy.shape[0] > 2e5:\n",
    "        infos.append(\"Aplicando K-means: reduciendo %s vectores a 10k centros.\" % big_npy.shape[0])\n",
    "        yield \"\\n\".join(infos)\n",
    "        try:\n",
    "            # MiniBatchKMeans es m√°s eficiente en memoria que KMeans regular\n",
    "            big_npy = (\n",
    "                MiniBatchKMeans(\n",
    "                    n_clusters=10000,          # Reducir a 10k centros\n",
    "                    verbose=True,              # Mostrar progreso\n",
    "                    batch_size=256 * config.n_cpu,  # Tama√±o de lote basado en CPUs\n",
    "                    compute_labels=False,      # No necesitamos las etiquetas\n",
    "                    init=\"random\",             # Inicializaci√≥n aleatoria\n",
    "                )\n",
    "                .fit(big_npy)\n",
    "                .cluster_centers_             # Solo guardamos los centros\n",
    "            )\n",
    "            print(f\"K-means completado. Nuevas dimensiones: {big_npy.shape}\")\n",
    "        except:\n",
    "            info = traceback.format_exc()\n",
    "            infos.append(f\"Error en K-means: {info}\")\n",
    "            yield \"\\n\".join(infos)\n",
    "\n",
    "    # Guardar las caracter√≠sticas procesadas\n",
    "    feature_file = \"%s/total_fea.npy\" % exp_dir\n",
    "    np.save(feature_file, big_npy)\n",
    "    print(f\"Caracter√≠sticas guardadas en: {feature_file}\")\n",
    "    \n",
    "    # Calcular par√°metros para el √≠ndice FAISS\n",
    "    # n_ivf: n√∫mero de clusters invertidos (afecta velocidad vs precisi√≥n)\n",
    "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
    "    infos.append(\"Forma de caracter√≠sticas: %s, Clusters IVF: %s\" % (big_npy.shape, n_ivf))\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    # Crear √≠ndice FAISS\n",
    "    # IVF = Inverted File (b√∫squeda aproximada r√°pida)\n",
    "    # Flat = b√∫squeda exacta dentro de cada cluster\n",
    "    dimension = 256 if version19 == \"v1\" else 768\n",
    "    index = faiss.index_factory(dimension, \"IVF%s,Flat\" % n_ivf)\n",
    "    \n",
    "    infos.append(\"Entrenando √≠ndice FAISS...\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    # Configurar par√°metros del √≠ndice\n",
    "    index_ivf = faiss.extract_index_ivf(index)\n",
    "    index_ivf.nprobe = 1  # N√∫mero de clusters a buscar (1 = m√°s r√°pido)\n",
    "    \n",
    "    # Entrenar el √≠ndice con las caracter√≠sticas\n",
    "    print(\"Entrenando √≠ndice FAISS...\")\n",
    "    index.train(big_npy)\n",
    "    \n",
    "    # Guardar √≠ndice entrenado (sin datos)\n",
    "    trained_index_path = (\n",
    "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "    faiss.write_index(index, trained_index_path)\n",
    "    print(f\"√çndice entrenado guardado: {trained_index_path}\")\n",
    "\n",
    "    infos.append(\"Agregando vectores al √≠ndice...\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    # Agregar vectores al √≠ndice en lotes para eficiencia de memoria\n",
    "    batch_size_add = 8192\n",
    "    total_vectors = big_npy.shape[0]\n",
    "    \n",
    "    print(f\"Agregando {total_vectors} vectores en lotes de {batch_size_add}...\")\n",
    "    for i in range(0, total_vectors, batch_size_add):\n",
    "        batch_end = min(i + batch_size_add, total_vectors)\n",
    "        index.add(big_npy[i:batch_end])\n",
    "        if i % (batch_size_add * 4) == 0:  # Progreso cada 4 lotes\n",
    "            print(f\"Progreso: {i}/{total_vectors} vectores agregados\")\n",
    "    \n",
    "    # Guardar √≠ndice completo (con datos)\n",
    "    final_index_path = (\n",
    "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "    faiss.write_index(index, final_index_path)\n",
    "    \n",
    "    # Mensaje de √©xito\n",
    "    success_msg = (\n",
    "        \"‚úÖ √çndice construido exitosamente: added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "    infos.append(success_msg)\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    print(f\"\\nüéâ √çNDICE COMPLETADO:\")\n",
    "    print(f\"üìÅ Archivo: {final_index_path}\")\n",
    "    print(f\"üìä Vectores: {total_vectors}\")\n",
    "    print(f\"üîç Clusters IVF: {n_ivf}\")\n",
    "    print(f\"üìê Dimensiones: {dimension}\")\n",
    "\n",
    "# Ejecutar construcci√≥n del √≠ndice\n",
    "print(\"üöÄ Iniciando construcci√≥n del √≠ndice FAISS...\")\n",
    "print(\"Este proceso puede tomar varios minutos dependiendo del tama√±o del dataset.\")\n",
    "\n",
    "training_log = train_index(model_name, 'v2')\n",
    "\n",
    "for line in training_log:\n",
    "    print(line)\n",
    "    if 'adding' in line.lower() or 'agregando' in line.lower():\n",
    "        clear_output()\n",
    "        display(Button(description=\"‚úÖ √çndice Completado\", button_style=\"success\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üñ•Ô∏è DETECCI√ìN Y CONFIGURACI√ìN AUTOM√ÅTICA DE GPU / AUTO GPU DETECTION & CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"üîç Detectando configuraci√≥n de GPU...\")\n",
    "\n",
    "# Verificar disponibilidad de CUDA y GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB\n",
    "    \n",
    "    print(f\"‚úÖ GPU detectada: {gpu_name}\")\n",
    "    print(f\"üìä Memoria GPU: {gpu_memory:.1f} GB\")\n",
    "    print(f\"üî¢ N√∫mero de GPUs: {gpu_count}\")\n",
    "    \n",
    "    # Configurar GPU seg√∫n hardware disponible\n",
    "    if gpu_count == 1:\n",
    "        gpus = \"0\"  # Una sola GPU\n",
    "        batch_size = 4 if gpu_memory >= 8 else 2  # Ajustar batch seg√∫n memoria\n",
    "    else:\n",
    "        gpus = \",\".join([str(i) for i in range(gpu_count)])  # Multi-GPU\n",
    "        batch_size = 6 if gpu_memory >= 8 else 4\n",
    "    \n",
    "    print(f\"‚öôÔ∏è Configuraci√≥n GPU: {gpus}\")\n",
    "    print(f\"üì¶ Batch Size ajustado: {batch_size}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No se detect√≥ GPU CUDA disponible\")\n",
    "    print(\"‚ö†Ô∏è ADVERTENCIA: RVC requiere GPU para entrenamiento eficiente\")\n",
    "    print(\"üí° Considera usar Google Colab o instalar CUDA\")\n",
    "    \n",
    "    # Configuraci√≥n fallback para CPU (no recomendado para entrenamiento)\n",
    "    gpus = \"0\"  # Forzar a intentar GPU 0\n",
    "    batch_size = 1\n",
    "    \n",
    "    print(f\"üîß Usando configuraci√≥n b√°sica: GPU={gpus}, Batch={batch_size}\")\n",
    "\n",
    "# Actualizar variables globales\n",
    "batch_size = batch_size  # Sobrescribir batch_size anterior si exist√≠a\n",
    "\n",
    "print(f\"‚úÖ Configuraci√≥n GPU completada: {gpus}\")\n",
    "print(f\"üìã Batch size final: {batch_size}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICACI√ìN FINAL DE CONFIGURACI√ìN SINGLE-GPU\n",
      "============================================================\n",
      "1. Variables de entorno:\n",
      "   ‚úÖ CUDA_VISIBLE_DEVICES: 0\n",
      "   ‚úÖ WORLD_SIZE: 1\n",
      "   ‚úÖ RANK: 0\n",
      "   ‚úÖ LOCAL_RANK: 0\n",
      "   ‚úÖ NCCL_P2P_DISABLE: 1\n",
      "   ‚úÖ NCCL_IB_DISABLE: 1\n",
      "\n",
      "2. Configuraci√≥n PyTorch:\n",
      "   ‚úÖ GPU activa: 0\n",
      "   ‚úÖ Nombre: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "   ‚úÖ Memoria: 6.0 GB\n",
      "   ‚úÖ CuDNN: True\n",
      "   üìä Memoria usada: 0.00 GB\n",
      "   üìä Memoria reservada: 0.00 GB\n",
      "   üìä Memoria libre: 6.00 GB\n",
      "   ‚úÖ Memoria suficiente para entrenamiento\n",
      "\n",
      "3. Configuraci√≥n RVC:\n",
      "   üìã model_name: My-Voice\n",
      "   üìã gpu_config: 0\n",
      "   üìã batch_size: 1\n",
      "   üìã sample_rate: 32k\n",
      "   üìã epochs: 300\n",
      "   üìã cache: False\n",
      "   üìã OV2: False\n",
      "\n",
      "4. Recomendaciones finales para RTX 4050:\n",
      "   üéØ Configuraci√≥n √ìPTIMA detectada:\n",
      "   ‚úÖ Batch size: 1 (apropiado)\n",
      "   ‚úÖ Cach√© GPU: False (correcto)\n",
      "   ‚úÖ GPU config: 0 (correcto)\n",
      "\n",
      "üéâ VERIFICACI√ìN COMPLETADA\n",
      "‚úÖ Sistema listo para entrenamiento single-GPU en RTX 4050\n",
      "üí° El entrenamiento deber√≠a ejecutarse sin errores de distributed training\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ‚úÖ VERIFICACI√ìN FINAL SINGLE-GPU PARA RTX 4050 / FINAL SINGLE-GPU CHECK\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"üîç VERIFICACI√ìN FINAL DE CONFIGURACI√ìN SINGLE-GPU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. VERIFICAR VARIABLES DE ENTORNO\n",
    "print(\"1. Variables de entorno:\")\n",
    "env_vars = [\n",
    "    'CUDA_VISIBLE_DEVICES', 'WORLD_SIZE', 'RANK', 'LOCAL_RANK',\n",
    "    'NCCL_P2P_DISABLE', 'NCCL_IB_DISABLE'\n",
    "]\n",
    "\n",
    "for var in env_vars:\n",
    "    value = os.environ.get(var, 'No configurado')\n",
    "    status = \"‚úÖ\" if var in os.environ else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {status} {var}: {value}\")\n",
    "\n",
    "# 2. VERIFICAR PYTORCH Y GPU\n",
    "print(\"\\n2. Configuraci√≥n PyTorch:\")\n",
    "if torch.cuda.is_available():\n",
    "    current_device = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    device_memory = torch.cuda.get_device_properties(current_device).total_memory / 1024**3\n",
    "    \n",
    "    print(f\"   ‚úÖ GPU activa: {current_device}\")\n",
    "    print(f\"   ‚úÖ Nombre: {device_name}\")\n",
    "    print(f\"   ‚úÖ Memoria: {device_memory:.1f} GB\")\n",
    "    print(f\"   ‚úÖ CuDNN: {torch.backends.cudnn.is_available()}\")\n",
    "    \n",
    "    # Test de memoria disponible\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        memory_cached = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        memory_free = device_memory - memory_cached\n",
    "        \n",
    "        print(f\"   üìä Memoria usada: {memory_allocated:.2f} GB\")\n",
    "        print(f\"   üìä Memoria reservada: {memory_cached:.2f} GB\")\n",
    "        print(f\"   üìä Memoria libre: {memory_free:.2f} GB\")\n",
    "        \n",
    "        if memory_free >= 4.0:\n",
    "            print(\"   ‚úÖ Memoria suficiente para entrenamiento\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è Memoria limitada - usar batch_size=1\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error verificando memoria: {e}\")\n",
    "else:\n",
    "    print(\"   ‚ùå GPU no disponible\")\n",
    "\n",
    "# 3. VERIFICAR CONFIGURACI√ìN RVC\n",
    "print(\"\\n3. Configuraci√≥n RVC:\")\n",
    "config_items = [\n",
    "    ('model_name', globals().get('model_name', 'No definido')),\n",
    "    ('gpu_config', globals().get('gpu_config', 'No definido')),\n",
    "    ('batch_size', globals().get('batch_size', 'No definido')),\n",
    "    ('sample_rate', globals().get('sample_rate', 'No definido')),\n",
    "    ('epochs', globals().get('epochs', 'No definido')),\n",
    "    ('cache', globals().get('cache', 'No definido')),\n",
    "    ('OV2', globals().get('OV2', 'No definido')),\n",
    "]\n",
    "\n",
    "for name, value in config_items:\n",
    "    print(f\"   üìã {name}: {value}\")\n",
    "\n",
    "# 4. RECOMENDACIONES FINALES\n",
    "print(\"\\n4. Recomendaciones finales para RTX 4050:\")\n",
    "print(\"   üéØ Configuraci√≥n √ìPTIMA detectada:\")\n",
    "\n",
    "# Verificar y ajustar configuraci√≥n final\n",
    "final_batch_size = globals().get('batch_size', 2)\n",
    "final_cache = globals().get('cache', False)\n",
    "final_gpu_config = globals().get('gpu_config', '0')\n",
    "\n",
    "if final_batch_size > 4:\n",
    "    print(\"   ‚ö†Ô∏è Batch size muy alto, se recomienda ‚â§2 para RTX 4050\")\n",
    "    final_batch_size = 2\n",
    "else:\n",
    "    print(f\"   ‚úÖ Batch size: {final_batch_size} (apropiado)\")\n",
    "\n",
    "if final_cache:\n",
    "    print(\"   ‚ö†Ô∏è Cach√© habilitado puede causar problemas de memoria\")\n",
    "    final_cache = False\n",
    "else:\n",
    "    print(f\"   ‚úÖ Cach√© GPU: {final_cache} (correcto)\")\n",
    "\n",
    "if final_gpu_config != \"0\":\n",
    "    print(\"   ‚ö†Ô∏è GPU config debe ser '0' para single-GPU\")\n",
    "    final_gpu_config = \"0\"\n",
    "else:\n",
    "    print(f\"   ‚úÖ GPU config: {final_gpu_config} (correcto)\")\n",
    "\n",
    "# Actualizar variables globales con valores corregidos\n",
    "globals()['batch_size'] = final_batch_size\n",
    "globals()['cache'] = final_cache\n",
    "globals()['gpu_config'] = final_gpu_config\n",
    "\n",
    "print(\"\\nüéâ VERIFICACI√ìN COMPLETADA\")\n",
    "print(\"‚úÖ Sistema listo para entrenamiento single-GPU en RTX 4050\")\n",
    "print(\"üí° El entrenamiento deber√≠a ejecutarse sin errores de distributed training\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "id": "ZsfjOgi8LKYM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CONFIGURANDO SINGLE-GPU PARA RTX 4050 LAPTOP\n",
      "============================================================\n",
      "‚úÖ Variables de entorno configuradas para single-GPU\n",
      "üñ•Ô∏è  GPU detectada: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "üíæ Memoria GPU: 6.0 GB\n",
      "üî¢ GPUs disponibles: 1 (usando solo GPU 0)\n",
      "‚öôÔ∏è  Configuraci√≥n GPU: 0\n",
      "üì¶ Batch Size optimizado: 1\n",
      "‚úÖ Test single-GPU exitoso\n",
      "üíæ Cach√© GPU: False (deshabilitado para ahorrar VRAM)\n",
      "üîÑ Mixed Precision: True (FP16 para ahorrar memoria)\n",
      "üö´ Distributed Training: False (deshabilitado)\n",
      "============================================================\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8888 (pid 16952), started 8 days, 0:10:41 ago. (Use '!kill 16952' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3d219d91993144e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3d219d91993144e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 8888;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO ENTRENAMIENTO SINGLE-GPU OPTIMIZADO PARA RTX 4050...\n",
      "======================================================================\n",
      "üìã CONFIGURACI√ìN FINAL SINGLE-GPU:\n",
      "   ‚Ä¢ Modelo: My-Voice\n",
      "   ‚Ä¢ Sample Rate: 32k\n",
      "   ‚Ä¢ Epochs: 300\n",
      "   ‚Ä¢ Batch Size: 1 (optimizado para 6GB VRAM)\n",
      "   ‚Ä¢ GPU Config: 0 (solo GPU 0)\n",
      "   ‚Ä¢ Guardar cada: 25 epochs\n",
      "   ‚Ä¢ Usar F0: S√≠ (pitch tracking habilitado)\n",
      "   ‚Ä¢ Versi√≥n: v2 (recomendado)\n",
      "   ‚Ä¢ Modelos OV2: No (False recomendado para RTX 4050)\n",
      "   ‚Ä¢ Cach√© GPU: False (deshabilitado para ahorrar VRAM)\n",
      "   ‚Ä¢ Mixed Precision: True (FP16 para eficiencia)\n",
      "   ‚Ä¢ Distributed: False (single-GPU forzado)\n",
      "======================================================================\n",
      "üîç Verificaci√≥n final de configuraci√≥n single-GPU:\n",
      "‚úÖ GPU Config correcta: solo GPU 0\n",
      "‚úÖ Batch Size seguro para RTX 4050: 1\n",
      "‚úÖ Cach√© GPU deshabilitado (correcto para 6GB VRAM)\n",
      "======================================================================\n",
      "Write filelist done\n",
      "Use gpus: 0\n",
      "√∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "√∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "√∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': 'assets/pretrained_v2/f0G32k.pth', 'pretrainD': 'assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 315, in _bootstrap\n",
      "self.run()\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 108, in run\n",
      "self._target(*self._args, **self._kwargs)\n",
      "File \"C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\\infer\\modules\\train\\train.py\", line 145, in run\n",
      "dist.init_process_group(\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 79, in wrapper\n",
      "return func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 93, in wrapper\n",
      "func_return = func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1361, in init_process_group\n",
      "store, rank, world_size = next(rendezvous_iterator)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 258, in _env_rendezvous_handler\n",
      "store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 185, in _create_c10d_store\n",
      "return TCPStore(\n",
      "RuntimeError: use_libuv was requested but PyTorch was build without libuv support\n",
      "INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': 'assets/pretrained_v2/f0G32k.pth', 'pretrainD': 'assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 315, in _bootstrap\n",
      "self.run()\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 108, in run\n",
      "self._target(*self._args, **self._kwargs)\n",
      "File \"C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\\infer\\modules\\train\\train.py\", line 145, in run\n",
      "dist.init_process_group(\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 79, in wrapper\n",
      "return func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 93, in wrapper\n",
      "func_return = func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1361, in init_process_group\n",
      "store, rank, world_size = next(rendezvous_iterator)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 258, in _env_rendezvous_handler\n",
      "store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 185, in _create_c10d_store\n",
      "return TCPStore(\n",
      "RuntimeError: use_libuv was requested but PyTorch was build without libuv support\n",
      "\n",
      "üéâ RESULTADO DEL ENTRENAMIENTO:\n",
      "======================================================================\n",
      "Entrenamiento finalizado, puede revisar los logs de entrenamiento en la consola o en train.log en la carpeta del experimento\n",
      "======================================================================\n",
      "\n",
      "üìã INFORMACI√ìN POST-ENTRENAMIENTO:\n",
      "üìÅ Archivos generados en: ./logs/My-Voice/\n",
      "üìä Monitoreo TensorBoard: http://localhost:8888\n",
      "üíæ Checkpoints guardados cada 25 epochs\n",
      "üéØ Modelo final: ./logs/My-Voice/G_300.pth\n",
      "üéµ Para inferencia, usa el archivo .pth generado\n",
      "======================================================================\n",
      "\n",
      "üéâ RESULTADO DEL ENTRENAMIENTO:\n",
      "======================================================================\n",
      "Entrenamiento finalizado, puede revisar los logs de entrenamiento en la consola o en train.log en la carpeta del experimento\n",
      "======================================================================\n",
      "\n",
      "üìã INFORMACI√ìN POST-ENTRENAMIENTO:\n",
      "üìÅ Archivos generados en: ./logs/My-Voice/\n",
      "üìä Monitoreo TensorBoard: http://localhost:8888\n",
      "üíæ Checkpoints guardados cada 25 epochs\n",
      "üéØ Modelo final: ./logs/My-Voice/G_300.pth\n",
      "üéµ Para inferencia, usa el archivo .pth generado\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üéì ENTRENAMIENTO DE MODELO RVC / RVC MODEL TRAINING\n",
    "# =============================================================================\n",
    "# Este c√≥digo implementa el entrenamiento completo de un modelo de conversi√≥n de voz\n",
    "# usando la arquitectura RVC (Retrieval-based Voice Conversion)\n",
    "\n",
    "#@title  **TRAIN YOUR MODEL** - You can also resume training here!\n",
    "\n",
    "# =============================================================================\n",
    "# üì¶ IMPORTACIONES NECESARIAS / REQUIRED IMPORTS\n",
    "# =============================================================================\n",
    "from random import shuffle      # Para mezclar datos aleatoriamente\n",
    "import json                    # Para manejar archivos de configuraci√≥n JSON\n",
    "import os                      # Para operaciones del sistema de archivos\n",
    "import pathlib                 # Para manejo moderno de rutas de archivos\n",
    "from subprocess import Popen, PIPE, STDOUT  # Para ejecutar procesos externos\n",
    "import torch                   # Para verificaci√≥n de GPU\n",
    "\n",
    "now_dir = os.getcwd()  # Obtener directorio actual de trabajo\n",
    "\n",
    "# =============================================================================\n",
    "# ‚öôÔ∏è CONFIGURACI√ìN DE PAR√ÅMETROS DE ENTRENAMIENTO / TRAINING PARAMETERS CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "# üîÑ Par√°metros principales de entrenamiento\n",
    "# model_name = 'My-Voice'  # Nombre del modelo (definido en celdas anteriores)\n",
    "\n",
    "# üíæ Frecuencia de guardado y duraci√≥n del entrenamiento\n",
    "save_frequency = 25    # @param {type:\"slider\", min:5, max:50, step:5}\n",
    "                      # Guardar checkpoint cada 25 epochs\n",
    "epochs = 300          # @param {type:\"slider\", min:10, max:2000, step:10} Se pueden usar 500\n",
    "                      # N√∫mero total de epochs de entrenamiento\n",
    "\n",
    "# üöÄ Configuraciones avanzadas\n",
    "OV2 = False           # @param {type:\"boolean\"} \n",
    "                     # Usar modelo OV2 Super (versi√≥n mejorada con mejor calidad)\n",
    "\n",
    "open_tensorboard = True  # @param{type:\"boolean\"}\n",
    "                        # Abrir TensorBoard para monitoreo en tiempo real\n",
    "\n",
    "# =============================================================================\n",
    "# üñ•Ô∏è CONFIGURACI√ìN FORZADA SINGLE-GPU PARA RTX 4050 / FORCED SINGLE-GPU CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# FORZAR CONFIGURACI√ìN SINGLE-GPU para evitar errores distributed training\n",
    "print(\"üîß CONFIGURANDO SINGLE-GPU PARA RTX 4050 LAPTOP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. CONFIGURAR VARIABLES DE ENTORNO para single-GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'        # Solo GPU 0 visible\n",
    "os.environ['WORLD_SIZE'] = '1'                  # Un solo proceso\n",
    "os.environ['RANK'] = '0'                        # Rank principal\n",
    "os.environ['LOCAL_RANK'] = '0'                  # Rank local 0\n",
    "os.environ['MASTER_ADDR'] = 'localhost'         # Direcci√≥n local\n",
    "os.environ['MASTER_PORT'] = '12355'             # Puerto libre\n",
    "\n",
    "# 2. DESHABILITAR backends distribuidos problem√°ticos\n",
    "os.environ['NCCL_P2P_DISABLE'] = '1'           # Deshabilitar P2P\n",
    "os.environ['NCCL_IB_DISABLE'] = '1'            # Deshabilitar InfiniBand\n",
    "\n",
    "print(\"‚úÖ Variables de entorno configuradas para single-GPU\")\n",
    "\n",
    "# 3. CONFIGURAR PyTorch para single-GPU\n",
    "if torch.cuda.is_available():\n",
    "    # Forzar uso de GPU 0 √∫nicamente\n",
    "    torch.cuda.set_device(0)\n",
    "    \n",
    "    # Configuraci√≥n optimizada para RTX 4050\n",
    "    torch.backends.cudnn.benchmark = False      # M√°s estable para batch peque√±o\n",
    "    torch.backends.cudnn.deterministic = True   # Reproducible\n",
    "    \n",
    "    # Obtener informaci√≥n de la GPU\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    \n",
    "    # CONFIGURACI√ìN ESPEC√çFICA PARA RTX 4050 (6GB VRAM)\n",
    "    gpu_config = \"0\"                            # Solo GPU 0\n",
    "    \n",
    "    # Batch size optimizado para 6GB VRAM\n",
    "    if gpu_memory >= 8:\n",
    "        batch_size = 4                          # Para GPUs con >8GB\n",
    "    elif gpu_memory >= 6:\n",
    "        batch_size = 2                          # Para RTX 4050 (6GB)\n",
    "    else:\n",
    "        batch_size = 1                          # Para GPUs con <6GB\n",
    "    \n",
    "    print(f\"üñ•Ô∏è  GPU detectada: {gpu_name}\")\n",
    "    print(f\"üíæ Memoria GPU: {gpu_memory:.1f} GB\")\n",
    "    print(f\"üî¢ GPUs disponibles: {gpu_count} (usando solo GPU 0)\")\n",
    "    print(f\"‚öôÔ∏è  Configuraci√≥n GPU: {gpu_config}\")\n",
    "    print(f\"üì¶ Batch Size optimizado: {batch_size}\")\n",
    "    \n",
    "    # Test de funcionamiento single-GPU\n",
    "    try:\n",
    "        test_tensor = torch.randn(2, 100).cuda()\n",
    "        result = test_tensor * 2\n",
    "        print(\"‚úÖ Test single-GPU exitoso\")\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en test GPU: {e}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå ADVERTENCIA: No se detect√≥ GPU CUDA\")\n",
    "    print(\"üí° Para RTX 4050, aseg√∫rate de:\")\n",
    "    print(\"   1. Tener drivers NVIDIA actualizados\")\n",
    "    print(\"   2. PyTorch con CUDA instalado:\")\n",
    "    print(\"      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    \n",
    "    # Configuraci√≥n fallback\n",
    "    gpu_config = \"0\"\n",
    "    batch_size = 1\n",
    "    print(f\"üîß Usando configuraci√≥n fallback...\")\n",
    "\n",
    "# 4. CONFIGURACIONES ADICIONALES para RTX 4050\n",
    "cache = False                                   # No usar cach√© GPU (ahorra VRAM)\n",
    "mixed_precision = True                          # Usar FP16 (reduce memoria 50%)\n",
    "use_distributed = False                         # NUNCA usar entrenamiento distribuido\n",
    "\n",
    "print(f\"üíæ Cach√© GPU: {cache} (deshabilitado para ahorrar VRAM)\")\n",
    "print(f\"üîÑ Mixed Precision: {mixed_precision} (FP16 para ahorrar memoria)\")\n",
    "print(f\"üö´ Distributed Training: {use_distributed} (deshabilitado)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# üéµ Configuraci√≥n de audio\n",
    "sample_rate = '32k'  # Frecuencia de muestreo (32kHz es √≥ptimo para la mayor√≠a de casos)\n",
    "\n",
    "# ü§ñ Selecci√≥n autom√°tica de modelos preentrenados seg√∫n configuraci√≥n\n",
    "if OV2:\n",
    "    # Modelos OV2 Super - versi√≥n mejorada con mejor calidad de audio\n",
    "    G_file = f'assets/pretrained_v2/f0Ov2Super{sample_rate}G.pth'  # Generador\n",
    "    D_file = f'assets/pretrained_v2/f0Ov2Super{sample_rate}D.pth'  # Discriminador\n",
    "else:\n",
    "    # Modelos est√°ndar v2\n",
    "    G_file = f'assets/pretrained_v2/f0G{sample_rate}.pth'\n",
    "    D_file = f'assets/pretrained_v2/f0D{sample_rate}.pth'\n",
    "\n",
    "# =============================================================================\n",
    "# üèóÔ∏è FUNCI√ìN PRINCIPAL DE ENTRENAMIENTO / MAIN TRAINING FUNCTION\n",
    "# =============================================================================\n",
    "def click_train(\n",
    "    exp_dir1,           # Nombre del experimento/modelo\n",
    "    sr2,                # Sample rate (frecuencia de muestreo)\n",
    "    if_f0_3,           # Si usar informaci√≥n F0 (pitch/tono)\n",
    "    spk_id5,           # ID del hablante (0 para un solo hablante)\n",
    "    save_epoch10,      # Frecuencia de guardado de checkpoints\n",
    "    total_epoch11,     # N√∫mero total de epochs\n",
    "    batch_size12,      # Tama√±o del batch/lote\n",
    "    if_save_latest13,  # Si guardar siempre el modelo m√°s reciente\n",
    "    pretrained_G14,    # Ruta del generador preentrenado\n",
    "    pretrained_D15,    # Ruta del discriminador preentrenado\n",
    "    gpus16,           # IDs de GPUs a usar (0 = primera GPU)\n",
    "    if_cache_gpu17,   # Si usar cach√© en GPU para acelerar entrenamiento\n",
    "    if_save_every_weights18,  # Si guardar pesos en cada checkpoint\n",
    "    version19,        # Versi√≥n del modelo (\"v1\" o \"v2\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Funci√≥n principal que ejecuta el entrenamiento del modelo RVC.\n",
    "    \n",
    "    Proceso:\n",
    "    1. Generar lista de archivos de entrenamiento (filelist)\n",
    "    2. Configurar par√°metros del modelo\n",
    "    3. Ejecutar script de entrenamiento\n",
    "    4. Monitorear progreso en tiempo real\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # üìÅ CONFIGURACI√ìN DE DIRECTORIOS / DIRECTORY SETUP\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Crear directorio del experimento\n",
    "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Definir rutas de directorios de datos\n",
    "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)      # Audio original (ground truth)\n",
    "    \n",
    "    # Seleccionar directorio de caracter√≠sticas seg√∫n versi√≥n del modelo\n",
    "    # v1 usa 256 dimensiones, v2 usa 768 dimensiones\n",
    "    feature_dir = (\n",
    "        \"%s/3_feature256\" % (exp_dir)  # Para modelo v1\n",
    "        if version19 == \"v1\"\n",
    "        else \"%s/3_feature768\" % (exp_dir)  # Para modelo v2\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # üéØ IDENTIFICACI√ìN DE ARCHIVOS V√ÅLIDOS / VALID FILES IDENTIFICATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    if if_f0_3:  # Si se usa informaci√≥n de pitch/tono\n",
    "        # Directorios adicionales para informaci√≥n F0\n",
    "        f0_dir = \"%s/2a_f0\" % (exp_dir)        # Archivos F0 b√°sicos\n",
    "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)  # Archivos F0 NSF (mejorados)\n",
    "        \n",
    "        # Encontrar archivos que tienen TODOS los componentes necesarios\n",
    "        # Usando intersecci√≥n de conjuntos para asegurar completitud\n",
    "        names = (\n",
    "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) &\n",
    "            set([name.split(\".\")[0] for name in os.listdir(feature_dir)]) &\n",
    "            set([name.split(\".\")[0] for name in os.listdir(f0_dir)]) &\n",
    "            set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
    "        )\n",
    "    else:  # Sin informaci√≥n de pitch\n",
    "        # Solo necesitamos audio original y caracter√≠sticas\n",
    "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
    "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
    "        )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # üìù GENERACI√ìN DE LISTA DE ENTRENAMIENTO / TRAINING LIST GENERATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    opt = []  # Lista que contendr√° todas las entradas de entrenamiento\n",
    "    \n",
    "    # Crear entrada para cada archivo v√°lido\n",
    "    for name in names:\n",
    "        if if_f0_3:  # Con informaci√≥n de pitch\n",
    "            # Formato: audio|caracter√≠sticas|f0|f0nsf|speaker_id\n",
    "            # Cada \"|\" separa un componente diferente del entrenamiento\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
    "                % (\n",
    "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,    # Audio original\n",
    "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,    # Caracter√≠sticas HuBERT\n",
    "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,         # Informaci√≥n F0\n",
    "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,      # Informaci√≥n F0 NSF\n",
    "                    spk_id5,                                     # ID del hablante\n",
    "                )\n",
    "            )\n",
    "        else:  # Sin informaci√≥n de pitch\n",
    "            # Formato simplificado: audio|caracter√≠sticas|speaker_id\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
    "                % (\n",
    "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,\n",
    "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,\n",
    "                    spk_id5,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # üîá AGREGAR ARCHIVOS \"MUTE\" PARA ESTABILIDAD / ADD MUTE FILES FOR STABILITY\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Determinar dimensi√≥n de caracter√≠sticas seg√∫n versi√≥n\n",
    "    fea_dim = 256 if version19 == \"v1\" else 768\n",
    "    \n",
    "    # Agregar archivos \"mute\" (silencio) para estabilizar el entrenamiento\n",
    "    # Estos archivos ayudan a que el modelo no se sobreajuste\n",
    "    if if_f0_3:\n",
    "        for _ in range(2):  # Agregar 2 entradas mute\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
    "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
    "            )\n",
    "    else:\n",
    "        for _ in range(2):\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
    "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
    "            )\n",
    "    \n",
    "    # Mezclar la lista para entrenamiento aleatorio (mejora la convergencia)\n",
    "    shuffle(opt)\n",
    "    \n",
    "    # Guardar lista de archivos de entrenamiento\n",
    "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
    "        f.write(\"\\n\".join(opt))\n",
    "\n",
    "    # =========================================================================\n",
    "    # üìä INFORMACI√ìN DE CONFIGURACI√ìN / CONFIGURATION INFO\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Mostrar informaci√≥n de la configuraci√≥n actual\n",
    "    print(\"Write filelist done\")\n",
    "    print(\"Use gpus:\", str(gpus16))\n",
    "    if pretrained_G14 == \"\":\n",
    "        print(\"No pretrained Generator\")\n",
    "    if pretrained_D15 == \"\":\n",
    "        print(\"No pretrained Discriminator\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # ‚öôÔ∏è CONFIGURACI√ìN DEL MODELO / MODEL CONFIGURATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Seleccionar archivo de configuraci√≥n seg√∫n versi√≥n y sample rate\n",
    "    if version19 == \"v1\" or sr2 == \"40k\":\n",
    "        config_path = \"configs/v1/%s.json\" % sr2\n",
    "    else:\n",
    "        config_path = \"configs/v2/%s.json\" % sr2\n",
    "    \n",
    "    # Copiar configuraci√≥n al directorio del experimento\n",
    "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
    "    if not pathlib.Path(config_save_path).exists():\n",
    "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            with open(config_path, \"r\") as config_file:\n",
    "                config_data = json.load(config_file)\n",
    "                json.dump(\n",
    "                    config_data,\n",
    "                    f,\n",
    "                    ensure_ascii=False,\n",
    "                    indent=4,\n",
    "                    sort_keys=True,\n",
    "                )\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # üöÄ CONSTRUCCI√ìN Y EJECUCI√ìN DEL COMANDO DE ENTRENAMIENTO / TRAINING COMMAND\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Construir comando de entrenamiento con todos los par√°metros\n",
    "    cmd = (\n",
    "        'python infer/modules/train/train.py '  # Script principal de entrenamiento\n",
    "        '-e \"%s\" '      # Directorio del experimento\n",
    "        '-sr %s '       # Sample rate\n",
    "        '-f0 %s '       # Usar F0 (1=s√≠, 0=no)\n",
    "        '-bs %s '       # Batch size\n",
    "        '-g %s '        # GPUs a usar\n",
    "        '-te %s '       # Total epochs\n",
    "        '-se %s '       # Save epochs (frecuencia de guardado)\n",
    "        '%s '           # Generador preentrenado (opcional)\n",
    "        '%s '           # Discriminador preentrenado (opcional)\n",
    "        '-l %s '        # Save latest (guardar √∫ltimo modelo)\n",
    "        '-c %s '        # Cache GPU\n",
    "        '-sw %s '       # Save weights (guardar pesos)\n",
    "        '-v %s'         # Versi√≥n del modelo\n",
    "        % (\n",
    "            exp_dir1,\n",
    "            sr2,\n",
    "            1 if if_f0_3 else 0,\n",
    "            batch_size12,\n",
    "            gpus16,\n",
    "            total_epoch11,\n",
    "            save_epoch10,\n",
    "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
    "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
    "            1 if if_save_latest13 == True else 0,\n",
    "            1 if if_cache_gpu17 == True else 0,\n",
    "            1 if if_save_every_weights18 == True else 0,\n",
    "            version19,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # üì∫ EJECUCI√ìN CON MONITOREO EN TIEMPO REAL / REAL-TIME MONITORING\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Ejecutar comando con captura de salida en tiempo real\n",
    "    # PIPE permite capturar tanto stdout como stderr\n",
    "    p = Popen(cmd, shell=True, cwd=now_dir, \n",
    "              stdout=PIPE, stderr=STDOUT, \n",
    "              bufsize=1, universal_newlines=True)\n",
    "\n",
    "    # Mostrar salida del entrenamiento en tiempo real\n",
    "    # Esto permite ver el progreso, p√©rdidas, y posibles errores\n",
    "    for line in p.stdout:\n",
    "        print(line.strip())\n",
    "\n",
    "    # Esperar a que termine el proceso de entrenamiento\n",
    "    p.wait()\n",
    "    \n",
    "    # Mensaje de finalizaci√≥n (traducido al espa√±ol)\n",
    "    return \"Entrenamiento finalizado, puede revisar los logs de entrenamiento en la consola o en train.log en la carpeta del experimento\"\n",
    "\n",
    "# =============================================================================\n",
    "# üìä CONFIGURACI√ìN DE TENSORBOARD PARA MONITOREO / TENSORBOARD MONITORING SETUP\n",
    "# =============================================================================\n",
    "\n",
    "if open_tensorboard:\n",
    "    # TensorBoard permite visualizar:\n",
    "    # - P√©rdidas del generador y discriminador en tiempo real\n",
    "    # - Espectrogramas de audio original vs generado\n",
    "    # - M√©tricas de entrenamiento y progreso\n",
    "    # - Gr√°ficas de learning rate y gradientes\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir ./logs --port=8888\n",
    "\n",
    "# =============================================================================\n",
    "# üéØ EJECUCI√ìN DEL ENTRENAMIENTO SINGLE-GPU / SINGLE-GPU TRAINING EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# CONFIGURACI√ìN FINAL OPTIMIZADA PARA RTX 4050 SINGLE-GPU\n",
    "print(\"üöÄ INICIANDO ENTRENAMIENTO SINGLE-GPU OPTIMIZADO PARA RTX 4050...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verificar que las variables est√©n definidas\n",
    "if \"cache\" not in locals():\n",
    "    cache = False  # Deshabilitado para RTX 4050 (ahorra VRAM)\n",
    "\n",
    "if \"mixed_precision\" not in locals():\n",
    "    mixed_precision = True  # Habilitar FP16 para ahorrar memoria\n",
    "\n",
    "print(f\"üìã CONFIGURACI√ìN FINAL SINGLE-GPU:\")\n",
    "print(f\"   ‚Ä¢ Modelo: {model_name}\")\n",
    "print(f\"   ‚Ä¢ Sample Rate: {sample_rate}\")\n",
    "print(f\"   ‚Ä¢ Epochs: {epochs}\")\n",
    "print(f\"   ‚Ä¢ Batch Size: {batch_size} (optimizado para 6GB VRAM)\")\n",
    "print(f\"   ‚Ä¢ GPU Config: {gpu_config} (solo GPU 0)\")\n",
    "print(f\"   ‚Ä¢ Guardar cada: {save_frequency} epochs\")\n",
    "print(f\"   ‚Ä¢ Usar F0: S√≠ (pitch tracking habilitado)\")\n",
    "print(f\"   ‚Ä¢ Versi√≥n: v2 (recomendado)\")\n",
    "print(f\"   ‚Ä¢ Modelos OV2: {'S√≠' if OV2 else 'No'} (False recomendado para RTX 4050)\")\n",
    "print(f\"   ‚Ä¢ Cach√© GPU: {cache} (deshabilitado para ahorrar VRAM)\")\n",
    "print(f\"   ‚Ä¢ Mixed Precision: {mixed_precision} (FP16 para eficiencia)\")\n",
    "print(f\"   ‚Ä¢ Distributed: False (single-GPU forzado)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# VERIFICACI√ìN FINAL DE CONFIGURACI√ìN SINGLE-GPU\n",
    "print(\"üîç Verificaci√≥n final de configuraci√≥n single-GPU:\")\n",
    "if gpu_config == \"0\":\n",
    "    print(\"‚úÖ GPU Config correcta: solo GPU 0\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Corrigiendo GPU Config a single-GPU...\")\n",
    "    gpu_config = \"0\"\n",
    "\n",
    "if batch_size <= 4:\n",
    "    print(f\"‚úÖ Batch Size seguro para RTX 4050: {batch_size}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Batch Size muy alto para RTX 4050, reduciendo...\")\n",
    "    batch_size = 2\n",
    "\n",
    "if not cache:\n",
    "    print(\"‚úÖ Cach√© GPU deshabilitado (correcto para 6GB VRAM)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Corrigiendo cach√© GPU...\")\n",
    "    cache = False\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# üöÄ EJECUTAR ENTRENAMIENTO con configuraci√≥n single-GPU optimizada\n",
    "training_log = click_train(\n",
    "    model_name,      # Nombre del modelo\n",
    "    sample_rate,     # '32k' - frecuencia de muestreo optimizada\n",
    "    True,           # if_f0_3 - usar informaci√≥n de pitch/tono (siempre True para calidad)\n",
    "    0,              # spk_id5 - ID del hablante (0 para single-speaker)\n",
    "    save_frequency, # Guardar checkpoint cada X epochs (25 recomendado)\n",
    "    epochs,         # N√∫mero total de epochs (300 balanceado)\n",
    "    batch_size,     # Tama√±o del lote optimizado para RTX 4050\n",
    "    True,           # if_save_latest13 - siempre guardar modelo m√°s reciente\n",
    "    G_file,         # Generador preentrenado (v2 est√°ndar)\n",
    "    D_file,         # Discriminador preentrenado (v2 est√°ndar)\n",
    "    gpu_config,     # \"0\" - configuraci√≥n single-GPU forzada\n",
    "    cache,          # False - sin cach√© para ahorrar VRAM\n",
    "    True,           # if_save_every_weights18 - guardar todos los checkpoints\n",
    "    'v2',           # version19 - usar modelo v2 (mejor calidad)\n",
    ")\n",
    "\n",
    "# Mostrar resultado final del entrenamiento\n",
    "print(\"\\nüéâ RESULTADO DEL ENTRENAMIENTO:\")\n",
    "print(\"=\" * 70)\n",
    "print(training_log)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# INFORMACI√ìN POST-ENTRENAMIENTO\n",
    "print(\"\\nüìã INFORMACI√ìN POST-ENTRENAMIENTO:\")\n",
    "print(\"üìÅ Archivos generados en: ./logs/{}/\".format(model_name))\n",
    "print(\"üìä Monitoreo TensorBoard: http://localhost:8888\")\n",
    "print(\"üíæ Checkpoints guardados cada {} epochs\".format(save_frequency))\n",
    "print(\"üéØ Modelo final: ./logs/{}/G_{}.pth\".format(model_name, epochs))\n",
    "print(\"üéµ Para inferencia, usa el archivo .pth generado\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CONFIGURANDO TENSORBOARD...\n",
      "‚úÖ TensorBoard disponible\n",
      "üìä Directorio de logs: ./RVC/logs/My-Voice\n",
      "‚ö†Ô∏è Directorio de logs no existe a√∫n - se crear√° durante el entrenamiento\n",
      "üìã Para iniciar TensorBoard manualmente:\n",
      "1. Ejecuta en terminal: tensorboard --logdir=./RVC/logs --port=8888\n",
      "2. O ejecuta la siguiente celda que contiene los comandos m√°gicos\n",
      "3. Abre http://localhost:8888 en tu navegador\n",
      "‚úÖ TensorBoard configurado - listo para entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# üîß CONFIGURACI√ìN TENSORBOARD CORREGIDA\n",
    "# Los comandos m√°gicos %load_ext y %tensorboard DEBEN ejecutarse en celdas separadas del notebook\n",
    "\n",
    "print(\"üîß CONFIGURANDO TENSORBOARD...\")\n",
    "\n",
    "# Verificar si TensorBoard est√° disponible\n",
    "try:\n",
    "    import tensorboard\n",
    "    print(\"‚úÖ TensorBoard disponible\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå TensorBoard no instalado, instalando...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"tensorboard\"])\n",
    "    import tensorboard\n",
    "    print(\"‚úÖ TensorBoard instalado exitosamente\")\n",
    "\n",
    "# Configurar directorio de logs para TensorBoard\n",
    "tensorboard_logdir = f\"./RVC/logs/{model_name}\"\n",
    "print(f\"üìä Directorio de logs: {tensorboard_logdir}\")\n",
    "\n",
    "# Verificar que existe el directorio de logs\n",
    "if os.path.exists(tensorboard_logdir):\n",
    "    print(\"‚úÖ Directorio de logs encontrado\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Directorio de logs no existe a√∫n - se crear√° durante el entrenamiento\")\n",
    "\n",
    "print(\"üìã Para iniciar TensorBoard manualmente:\")\n",
    "print(\"1. Ejecuta en terminal: tensorboard --logdir=./RVC/logs --port=8888\")\n",
    "print(\"2. O ejecuta la siguiente celda que contiene los comandos m√°gicos\")\n",
    "print(\"3. Abre http://localhost:8888 en tu navegador\")\n",
    "print(\"‚úÖ TensorBoard configurado - listo para entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1daf3bbc71656237\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1daf3bbc71656237\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8888;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorBoard iniciado en: http://localhost:8888\n",
      "üî• Abre esa URL en tu navegador para monitorear el entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# üìä INICIAR TENSORBOARD (Comandos m√°gicos en celda separada)\n",
    "# EJECUTA ESTA CELDA ANTES DEL ENTRENAMIENTO\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./RVC/logs --port 8888\n",
    "\n",
    "print(\"‚úÖ TensorBoard iniciado en: http://localhost:8888\")\n",
    "print(\"üî• Abre esa URL en tu navegador para monitorear el entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO ENTRENAMIENTO RVC - CONFIGURACI√ìN SINGLE-GPU RTX 4050\n",
      "======================================================================\n",
      "üìÅ Modelo: My-Voice\n",
      "üéµ Sample Rate: 32k\n",
      "üî¢ Epochs: 300\n",
      "üì¶ Batch Size: 1\n",
      "üéõÔ∏è F0: Activado\n",
      "üíæ Cache GPU: Desactivado\n",
      "üìä TensorBoard: Activado\n",
      "======================================================================\n",
      "üêç Python ejecutable: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\Scripts\\python.exe\n",
      "üóÇÔ∏è Python version: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "üì¶ Python path: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\n",
      "üìÇ Directorio actual: C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\n",
      "‚úÖ Directorio RVC confirmado - todos los elementos necesarios presentes\n",
      "‚úÖ Script de entrenamiento modificado correctamente para single-GPU\n",
      "‚úÖ PyTorch disponible: 2.4.1+cu121\n",
      "‚úÖ CUDA disponible: 12.1\n",
      "‚úÖ Ejecutando desde directorio RVC: C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\n",
      "üéØ Comando de entrenamiento:\n",
      "c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\Scripts\\python.exe infer/modules/train/train.py -e My-Voice -sr 32k -f0 1 -bs 1 -te 300 -se 25 -pg ./assets/pretrained_v2/f0G32k.pth -pd ./assets/pretrained_v2/f0D32k.pth -l 0 -c 0 -sw 1 -v v2\n",
      "üî• INICIANDO ENTRENAMIENTO...\n",
      "üìä Monitorea el progreso en TensorBoard: http://localhost:8888\n",
      "‚è±Ô∏è El entrenamiento puede tomar varias horas dependiendo del dataset y epochs\n",
      "üîÑ Ejecutando con variables de entorno configuradas para single-GPU...\n",
      "‚ùå ERROR EN EL ENTRENAMIENTO:\n",
      "üì• Return code: 1\n",
      "\n",
      "üì§ STDOUT:\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß SINGLE-GPU DETECTED: Running direct training (no multiprocessing)\n",
      "   INFO:My-Voice:√∞≈∏‚Äù¬ß SINGLE-GPU TRAINING STARTED\n",
      "   INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': './assets/pretrained_v2/f0G32k.pth', 'pretrainD': './assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 0, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "   DEBUG:infer.lib.infer_pack.models:gin_channels: 256, self.spk_embed_dim: 109\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0G32k.pth\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0D32k.pth\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   INFO:My-Voice:Train Epoch: 1 [0/333 (0%)]\tLoss_disc: 3.346714\tLoss_gen: 3.196678\tLoss_fm: 18.669750\tLoss_mel: 29.484741\tLoss_kl: 14.747654\tLR: 0.000100\t[2025-07-16 22:31:20] | (0:00:03.902409)\n",
      "\n",
      "üö® STDERR:\n",
      "   Traceback (most recent call last):\n",
      "     File \"infer/modules/train/train.py\", line 1142, in <module>\n",
      "       main()\n",
      "     File \"infer/modules/train/train.py\", line 126, in main\n",
      "       run_single_gpu(0, hps, logger)\n",
      "     File \"infer/modules/train/train.py\", line 270, in run_single_gpu\n",
      "       train_and_evaluate_single_gpu(\n",
      "     File \"infer/modules/train/train.py\", line 544, in train_and_evaluate_single_gpu\n",
      "       if global_step % hps.train.eval_interval == 0:\n",
      "   AttributeError: 'HParams' object has no attribute 'eval_interval'\n",
      "üèÅ Proceso de entrenamiento finalizado\n",
      "‚ùå ERROR EN EL ENTRENAMIENTO:\n",
      "üì• Return code: 1\n",
      "\n",
      "üì§ STDOUT:\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß SINGLE-GPU DETECTED: Running direct training (no multiprocessing)\n",
      "   INFO:My-Voice:√∞≈∏‚Äù¬ß SINGLE-GPU TRAINING STARTED\n",
      "   INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': './assets/pretrained_v2/f0G32k.pth', 'pretrainD': './assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 0, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "   DEBUG:infer.lib.infer_pack.models:gin_channels: 256, self.spk_embed_dim: 109\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0G32k.pth\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0D32k.pth\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   √∞≈∏‚Äù¬ß PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   INFO:My-Voice:Train Epoch: 1 [0/333 (0%)]\tLoss_disc: 3.346714\tLoss_gen: 3.196678\tLoss_fm: 18.669750\tLoss_mel: 29.484741\tLoss_kl: 14.747654\tLR: 0.000100\t[2025-07-16 22:31:20] | (0:00:03.902409)\n",
      "\n",
      "üö® STDERR:\n",
      "   Traceback (most recent call last):\n",
      "     File \"infer/modules/train/train.py\", line 1142, in <module>\n",
      "       main()\n",
      "     File \"infer/modules/train/train.py\", line 126, in main\n",
      "       run_single_gpu(0, hps, logger)\n",
      "     File \"infer/modules/train/train.py\", line 270, in run_single_gpu\n",
      "       train_and_evaluate_single_gpu(\n",
      "     File \"infer/modules/train/train.py\", line 544, in train_and_evaluate_single_gpu\n",
      "       if global_step % hps.train.eval_interval == 0:\n",
      "   AttributeError: 'HParams' object has no attribute 'eval_interval'\n",
      "üèÅ Proceso de entrenamiento finalizado\n"
     ]
    }
   ],
   "source": [
    "# üéØ ENTRENAR MODELO RVC CON TODAS LAS CORRECCIONES APLICADAS\n",
    "# ========================================================================\n",
    "# ‚úÖ CORRECCIONES IMPLEMENTADAS:\n",
    "# 1. Single-GPU training sin distributed/multiprocessing (elimina error libuv)\n",
    "# 2. TensorBoard program√°tico sin comandos m√°gicos problem√°ticos\n",
    "# 3. Configuraci√≥n optimizada para RTX 4050 laptop\n",
    "# 4. Rutas simplificadas - ya estamos en el directorio RVC\n",
    "# 5. Ambiente Python correcto - usando sys.executable del notebook\n",
    "# 6. Manejo de eval_interval faltante en configuraci√≥n HParams\n",
    "# ========================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Definir variables faltantes usando los valores de variables del kernel\n",
    "final_batch_size = globals().get('batch_size', 2)\n",
    "final_cache = globals().get('cache', False)\n",
    "use_f0 = True  # Para entrenamiento de voz humana siempre usar F0\n",
    "\n",
    "print(\"üöÄ INICIANDO ENTRENAMIENTO RVC - CONFIGURACI√ìN SINGLE-GPU RTX 4050\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìÅ Modelo: {model_name}\")\n",
    "print(f\"üéµ Sample Rate: {sample_rate}\")\n",
    "print(f\"üî¢ Epochs: {epochs}\")\n",
    "print(f\"üì¶ Batch Size: {final_batch_size}\")\n",
    "print(f\"üéõÔ∏è F0: {'Activado' if use_f0 else 'Desactivado'}\")\n",
    "print(f\"üíæ Cache GPU: {'Activado' if final_cache else 'Desactivado'}\")\n",
    "print(f\"üìä TensorBoard: {'Activado' if open_tensorboard else 'Desactivado'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verificar ambiente Python\n",
    "python_executable = sys.executable\n",
    "print(f\"üêç Python ejecutable: {python_executable}\")\n",
    "print(f\"üóÇÔ∏è Python version: {sys.version}\")\n",
    "print(f\"üì¶ Python path: {sys.prefix}\")\n",
    "\n",
    "# Verificar directorio actual - debemos estar en RVC\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìÇ Directorio actual: {current_dir}\")\n",
    "\n",
    "# Verificar que estamos en el directorio RVC correcto\n",
    "required_items = [\"infer\", \"assets\", \"logs\"]\n",
    "missing_items = [item for item in required_items if not os.path.exists(item)]\n",
    "\n",
    "if missing_items:\n",
    "    print(f\"‚ùå Faltan elementos RVC: {missing_items}\")\n",
    "    print(\"üìÅ Contenido del directorio actual:\")\n",
    "    for item in os.listdir(current_dir):\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "    raise FileNotFoundError(f\"Directorio RVC incompleto. Faltan: {missing_items}\")\n",
    "else:\n",
    "    print(\"‚úÖ Directorio RVC confirmado - todos los elementos necesarios presentes\")\n",
    "\n",
    "# Verificar script de entrenamiento modificado\n",
    "train_script_path = \"infer/modules/train/train.py\"\n",
    "if os.path.exists(train_script_path):\n",
    "    with open(train_script_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        if \"üîß PARCHE SINGLE-GPU APLICADO\" in content and \"run_single_gpu\" in content:\n",
    "            print(\"‚úÖ Script de entrenamiento modificado correctamente para single-GPU\")\n",
    "            \n",
    "            # Verificar correcci√≥n espec√≠fica de eval_interval\n",
    "            if \"getattr(hps.train, 'eval_interval'\" in content:\n",
    "                print(\"‚úÖ Correcci√≥n eval_interval aplicada correctamente\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Correcci√≥n eval_interval faltante - podr√≠a causar errores\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Script de entrenamiento no modificado - usando versi√≥n original\")\n",
    "else:\n",
    "    print(f\"‚ùå Script de entrenamiento no encontrado: {train_script_path}\")\n",
    "\n",
    "# Verificar disponibilidad de dependencias en el ambiente actual\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"‚úÖ PyTorch disponible: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ CUDA disponible: {torch.version.cuda}\")\n",
    "        \n",
    "        # Informaci√≥n detallada de GPU para debugging\n",
    "        device = torch.cuda.current_device()\n",
    "        gpu_name = torch.cuda.get_device_name(device)\n",
    "        memory_total = torch.cuda.get_device_properties(device).total_memory / 1024**3\n",
    "        print(f\"‚úÖ GPU activa: {gpu_name} ({memory_total:.1f}GB)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è CUDA no disponible en este ambiente\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importando PyTorch: {e}\")\n",
    "\n",
    "# Verificar dataset y archivos de entrenamiento\n",
    "model_logs_path = f\"./logs/{model_name}\"\n",
    "if os.path.exists(model_logs_path):\n",
    "    filelist_path = f\"{model_logs_path}/filelist.txt\"\n",
    "    if os.path.exists(filelist_path):\n",
    "        with open(filelist_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"‚úÖ Filelist encontrado: {len(lines)} archivos de entrenamiento\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Filelist no encontrado - podr√≠a necesitar regeneraci√≥n\")\n",
    "    \n",
    "    # Verificar directorios de datos necesarios\n",
    "    data_dirs = [\"0_gt_wavs\", \"2a_f0\", \"2b-f0nsf\", \"3_feature768\"]\n",
    "    for data_dir in data_dirs:\n",
    "        dir_path = f\"{model_logs_path}/{data_dir}\"\n",
    "        if os.path.exists(dir_path):\n",
    "            file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
    "            print(f\"‚úÖ {data_dir}: {file_count} archivos\")\n",
    "        else:\n",
    "            print(f\"‚ùå {data_dir}: directorio faltante\")\n",
    "else:\n",
    "    print(f\"‚ùå Directorio del modelo no encontrado: {model_logs_path}\")\n",
    "\n",
    "# Ejecutar entrenamiento directamente desde el directorio RVC actual\n",
    "try:\n",
    "    print(f\"‚úÖ Ejecutando desde directorio RVC: {os.getcwd()}\")\n",
    "    \n",
    "    # Configurar variables de entorno para single-GPU\n",
    "    env = os.environ.copy()\n",
    "    env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    env[\"WORLD_SIZE\"] = \"1\"\n",
    "    env[\"RANK\"] = \"0\"\n",
    "    env[\"LOCAL_RANK\"] = \"0\"\n",
    "    \n",
    "    # Limpiar cach√© CUDA antes de iniciar\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"‚úÖ Cach√© CUDA limpiado antes del entrenamiento\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Construir comando de entrenamiento con el Python correcto del ambiente\n",
    "    train_command = [\n",
    "        python_executable,  # Usar el mismo Python del notebook\n",
    "        \"infer/modules/train/train.py\",\n",
    "        \"-e\", model_name,\n",
    "        \"-sr\", sample_rate,\n",
    "        \"-f0\", \"1\" if use_f0 else \"0\",\n",
    "        \"-bs\", str(final_batch_size),\n",
    "        \"-te\", str(epochs),\n",
    "        \"-se\", str(save_frequency),\n",
    "        \"-pg\", \"./assets/pretrained_v2/f0G32k.pth\",\n",
    "        \"-pd\", \"./assets/pretrained_v2/f0D32k.pth\",\n",
    "        \"-l\", \"1\" if final_cache else \"0\",\n",
    "        \"-c\", \"0\",  # single-GPU\n",
    "        \"-sw\", \"1\",  # save weights\n",
    "        \"-v\", \"v2\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"üéØ Comando de entrenamiento:\")\n",
    "    print(\" \".join(train_command))\n",
    "    print(\"üî• INICIANDO ENTRENAMIENTO...\")\n",
    "    print(\"üìä Monitorea el progreso en TensorBoard: http://localhost:8888\")\n",
    "    print(\"‚è±Ô∏è El entrenamiento puede tomar varias horas dependiendo del dataset y epochs\")\n",
    "    print(\"üîÑ Ejecutando con variables de entorno configuradas para single-GPU...\")\n",
    "    \n",
    "    # Ejecutar entrenamiento con el ambiente correcto\n",
    "    result = subprocess.run(\n",
    "        train_command, \n",
    "        capture_output=True, \n",
    "        text=True, \n",
    "        env=env,  # Pasar variables de entorno configuradas\n",
    "        cwd=current_dir  # Asegurar directorio de trabajo correcto\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ ENTRENAMIENTO COMPLETADO CON √âXITO!\")\n",
    "        print(\"üìÅ Modelos guardados en: ./logs/\")\n",
    "        print(\"üéµ Listo para usar en inferencia!\")\n",
    "        \n",
    "        # Mostrar algunas l√≠neas finales del log si est√° disponible\n",
    "        if result.stdout:\n",
    "            print(\"\\nüìã √öLTIMAS L√çNEAS DEL LOG:\")\n",
    "            stdout_lines = result.stdout.strip().split('\\n')\n",
    "            for line in stdout_lines[-10:]:  # √öltimas 10 l√≠neas\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(\"‚ùå ERROR EN EL ENTRENAMIENTO:\")\n",
    "        print(f\"üì• Return code: {result.returncode}\")\n",
    "        \n",
    "        if result.stdout:\n",
    "            print(\"\\nüì§ STDOUT:\")\n",
    "            stdout_lines = result.stdout.strip().split('\\n')\n",
    "            for line in stdout_lines[-25:]:  # √öltimas 25 l√≠neas del stdout\n",
    "                print(f\"   {line}\")\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"\\nüö® STDERR:\")\n",
    "            stderr_lines = result.stderr.strip().split('\\n')\n",
    "            for line in stderr_lines[-15:]:  # √öltimas 15 l√≠neas del stderr\n",
    "                print(f\"   {line}\")\n",
    "        \n",
    "        # An√°lisis espec√≠fico de errores conocidos\n",
    "        full_output = (result.stdout or \"\") + (result.stderr or \"\")\n",
    "        \n",
    "        if \"use_libuv was requested but PyTorch was build without libuv support\" in full_output:\n",
    "            print(\"\\nüîß ERROR DETECTADO: libuv\")\n",
    "            print(\"üí° SOLUCI√ìN: Verificar que el script train.py est√© modificado para single-GPU\")\n",
    "        \n",
    "        if \"No module named\" in full_output:\n",
    "            print(\"\\nüîß ERROR DETECTADO: M√≥dulo faltante\")\n",
    "            print(\"üí° SOLUCI√ìN: Instalar dependencias en el ambiente actual\")\n",
    "        \n",
    "        if \"CUDA\" in full_output and \"not available\" in full_output:\n",
    "            print(\"\\nüîß ERROR DETECTADO: CUDA no disponible\")\n",
    "            print(\"üí° SOLUCI√ìN: Verificar instalaci√≥n de PyTorch con CUDA\")\n",
    "            \n",
    "        if \"AttributeError\" in full_output and \"eval_interval\" in full_output:\n",
    "            print(\"\\nüîß ERROR DETECTADO: eval_interval faltante\")\n",
    "            print(\"üí° SOLUCI√ìN: Script train.py necesita correcci√≥n adicional\")\n",
    "            \n",
    "        if \"FileNotFoundError\" in full_output:\n",
    "            print(\"\\nüîß ERROR DETECTADO: Archivo no encontrado\")\n",
    "            print(\"üí° SOLUCI√ìN: Verificar que todos los archivos de preprocesamiento est√©n presentes\")\n",
    "            \n",
    "        if \"RuntimeError\" in full_output and (\"CUDA\" in full_output or \"GPU\" in full_output):\n",
    "            print(\"\\nüîß ERROR DETECTADO: Error de GPU/CUDA\")\n",
    "            print(\"üí° SOLUCI√ìN: Verificar memoria GPU disponible o reducir batch_size\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"‚èπÔ∏è Entrenamiento interrumpido por el usuario\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error durante el entrenamiento: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"üèÅ Proceso de entrenamiento finalizado\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
