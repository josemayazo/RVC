{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cRMphhqG-C5"
   },
   "source": [
    "<h1><center> Retrieval based Voice Conversion WebUI Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFFCx5J80SGa"
   },
   "source": [
    "vist original colab here -> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jwu07JgqoFON"
   },
   "outputs": [],
   "source": [
    "# @title mount drive (optional)\n",
    "\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets antlr4-python3-runtime==4.9.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/antlr4-go/antlr.git\n",
    "# !pip install ipywidgets antlr4-python3-runtime==4.9.3 scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a12f6952c4d46f3a04608ffbeb45311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='✔ Success', style=ButtonStyle())"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title install (Windows compatible)\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Button\n",
    "import subprocess, shlex, os, sys\n",
    "\n",
    "var = \"WebUI\"\n",
    "test = \"Voice\"\n",
    "c_word = \"Conversion\"\n",
    "r_word = \"Retrieval\"\n",
    "\n",
    "repo_url = f\"https://github.com/RVC-Project/{r_word}-based-{test}-{c_word}-{var}\"\n",
    "repo_dir = os.path.join(os.getcwd(), \"RVC_\")\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir])\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "pretrains = [\"f0D32k.pth\", \"f0G32k.pth\"]\n",
    "new_pretrains = [\"f0Ov2Super32kD.pth\", \"f0Ov2Super32kG.pth\"]\n",
    "\n",
    "pretrain_dir = os.path.join(repo_dir, \"assets\", \"pretrained_v2\")\n",
    "os.makedirs(pretrain_dir, exist_ok=True)\n",
    "\n",
    "def download_file(url, output_path):\n",
    "    if sys.platform == \"win32\":\n",
    "        # Use curl for Windows\n",
    "        cmd = f'curl -L \"{url}\" -o \"{output_path}\"'\n",
    "    else:\n",
    "        # Use aria2c for Linux\n",
    "        cmd = f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}\" -d \"{os.path.dirname(output_path)}\" -o \"{os.path.basename(output_path)}\"'\n",
    "    try:\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "for file in pretrains:\n",
    "    dest = os.path.join(pretrain_dir, file)\n",
    "    if not os.path.exists(dest):\n",
    "        url = f\"https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/{file}\"\n",
    "        download_file(url, dest)\n",
    "\n",
    "for file in new_pretrains:\n",
    "    dest = os.path.join(pretrain_dir, file)\n",
    "    if not os.path.exists(dest):\n",
    "        url = f\"https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/{file}\"\n",
    "        download_file(url, dest)\n",
    "\n",
    "# Install dependencies\n",
    "if sys.platform == \"win32\":\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pip==23.3.1\"])\n",
    "    subprocess.run([\"git\", \"pull\"])\n",
    "    subprocess.run([\"curl\", \"-L\", \"https://huggingface.co/Rejekts/project/resolve/main/download_files.py\", \"-o\", os.path.join(repo_dir, \"download_files.py\")])\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"yt_dlp\"])\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pytube\", \"pydub\", \"gradio==3.42.0\"])\n",
    "    subprocess.run([sys.executable, \"download_files.py\"])\n",
    "    subprocess.run([sys.executable, \"tools/download_models.py\"])\n",
    "else:\n",
    "    !pip install pip==23.3.1\n",
    "    !git pull\n",
    "    !wget -nc https://huggingface.co/Rejekts/project/resolve/main/download_files.py -O ./download_files.py\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install yt_dlp\n",
    "    !pip install pytube pydub gradio==3.42.0\n",
    "    !python ./download_files.py\n",
    "    !python ./tools/download_models.py\n",
    "\n",
    "clear_output()\n",
    "Button(description=\"\\u2714 Success\", button_style=\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWwACtu5KZzV"
   },
   "source": [
    "# Training No UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertido: Audio 1.mp3 -> Audio 1.wav\n",
      "Convertido: Audio 10.mp3 -> Audio 10.wav\n",
      "Convertido: Audio 11.mp3 -> Audio 11.wav\n",
      "Convertido: Audio 12.mp3 -> Audio 12.wav\n",
      "Convertido: Audio 13.mp3 -> Audio 13.wav\n",
      "Convertido: Audio 11.mp3 -> Audio 11.wav\n",
      "Convertido: Audio 12.mp3 -> Audio 12.wav\n",
      "Convertido: Audio 13.mp3 -> Audio 13.wav\n",
      "Convertido: Audio 14.mp3 -> Audio 14.wav\n",
      "Convertido: Audio 15.mp3 -> Audio 15.wav\n",
      "Convertido: Audio 16.mp3 -> Audio 16.wav\n",
      "Convertido: Audio 14.mp3 -> Audio 14.wav\n",
      "Convertido: Audio 15.mp3 -> Audio 15.wav\n",
      "Convertido: Audio 16.mp3 -> Audio 16.wav\n",
      "Convertido: Audio 17.mp3 -> Audio 17.wav\n",
      "Convertido: Audio 18.mp3 -> Audio 18.wav\n",
      "Convertido: Audio 19.mp3 -> Audio 19.wav\n",
      "Convertido: Audio 17.mp3 -> Audio 17.wav\n",
      "Convertido: Audio 18.mp3 -> Audio 18.wav\n",
      "Convertido: Audio 19.mp3 -> Audio 19.wav\n",
      "Convertido: Audio 2.mp3 -> Audio 2.wav\n",
      "Convertido: Audio 20.mp3 -> Audio 20.wav\n",
      "Convertido: Audio 2.mp3 -> Audio 2.wav\n",
      "Convertido: Audio 20.mp3 -> Audio 20.wav\n",
      "Convertido: Audio 3.mp3 -> Audio 3.wav\n",
      "Convertido: Audio 4.mp3 -> Audio 4.wav\n",
      "Convertido: Audio 3.mp3 -> Audio 3.wav\n",
      "Convertido: Audio 4.mp3 -> Audio 4.wav\n",
      "Convertido: Audio 5.mp3 -> Audio 5.wav\n",
      "Convertido: Audio 6.mp3 -> Audio 6.wav\n",
      "Convertido: Audio 5.mp3 -> Audio 5.wav\n",
      "Convertido: Audio 6.mp3 -> Audio 6.wav\n",
      "Convertido: Audio 7.mp3 -> Audio 7.wav\n",
      "Convertido: Audio 8.mp3 -> Audio 8.wav\n",
      "Convertido: Audio 7.mp3 -> Audio 7.wav\n",
      "Convertido: Audio 8.mp3 -> Audio 8.wav\n",
      "Convertido: Audio 9.mp3 -> Audio 9.wav\n",
      "Convertido: Audio 9.mp3 -> Audio 9.wav\n"
     ]
    }
   ],
   "source": [
    "# Convert to wav\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "from pydub.utils import which\n",
    "\n",
    "# Configurar FFmpeg\n",
    "AudioSegment.converter = which(\"ffmpeg\")\n",
    "\n",
    "input_folder = r'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset'\n",
    "output_folder = r'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset_wav'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith('.mp3'):\n",
    "        mp3_path = f\"{input_folder}/{filename}\"\n",
    "        wav_filename = os.path.splitext(filename)[0] + '.wav'\n",
    "        wav_path = f\"{output_folder}/{wav_filename}\"\n",
    "        try:\n",
    "            audio = AudioSegment.from_mp3(mp3_path)\n",
    "            audio.export(wav_path, format='wav')\n",
    "            print(f'Convertido: {filename} -> {wav_filename}')\n",
    "        except FileNotFoundError:\n",
    "            print(f'Error: FFmpeg no está instalado o no está en el PATH del sistema.')\n",
    "        except Exception as e:\n",
    "            print(f'Error con {filename}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 RVC Path: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect\\RVC\n",
      "📂 Directorio original: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\n",
      "📂 Cambiado a directorio RVC: C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\n",
      "📥 Importando función de preprocesamiento...\n",
      "✅ Función preprocess_trainset importada exitosamente\n",
      "\n",
      "📋 CONFIGURACIÓN DE PREPROCESAMIENTO:\n",
      "   • Dataset de entrada: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset_wav\n",
      "   • Modelo: My-Voice\n",
      "   • Sample rate: 32000 Hz\n",
      "   • Hilos de procesamiento: 2\n",
      "   • Directorio de salida: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect/RVC/logs/My-Voice\n",
      "   • Uso de F0: False\n",
      "   • Umbral F0: 3.0\n",
      "✅ Dataset encontrado: 20 archivos WAV\n",
      "   Primeros archivos: ['Audio 1.wav', 'Audio 10.wav', 'Audio 11.wav']\n",
      "\n",
      "🚀 Iniciando preprocesamiento del dataset...\n",
      "Este proceso puede tardar varios minutos dependiendo del tamaño del dataset\n",
      "start preprocess\n",
      "end preprocess\n",
      "\n",
      "✅ PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\n",
      "📁 Archivos generados en: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect/RVC/logs/My-Voice\n",
      "📂 Subdirectorios creados: ['0_gt_wavs', '1_16k_wavs', '2a_f0', '2b-f0nsf', '3_feature768']\n",
      "   • 0_gt_wavs: 331 archivos\n",
      "   • 1_16k_wavs: 331 archivos\n",
      "   • 2a_f0: 331 archivos\n",
      "   • 2b-f0nsf: 331 archivos\n",
      "   • 3_feature768: 331 archivos\n",
      "\n",
      "📂 Restaurado al directorio original: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\n",
      "end preprocess\n",
      "\n",
      "✅ PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\n",
      "📁 Archivos generados en: C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect/RVC/logs/My-Voice\n",
      "📂 Subdirectorios creados: ['0_gt_wavs', '1_16k_wavs', '2a_f0', '2b-f0nsf', '3_feature768']\n",
      "   • 0_gt_wavs: 331 archivos\n",
      "   • 1_16k_wavs: 331 archivos\n",
      "   • 2a_f0: 331 archivos\n",
      "   • 2b-f0nsf: 331 archivos\n",
      "   • 3_feature768: 331 archivos\n",
      "\n",
      "📂 Restaurado al directorio original: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 🔧 PREPROCESAMIENTO DEL DATASET / DATASET PREPROCESSING\n",
    "# =============================================================================\n",
    "# Esta celda prepara el dataset de audio para el entrenamiento RVC\n",
    "# Incluye configuración de paths, normalización de audio y extracción inicial\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# =============================================================================\n",
    "# 📁 CONFIGURACIÓN DE RUTAS Y PATHS / PATH CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Configurar rutas principales del proyecto\n",
    "curr_path = 'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_proyect'\n",
    "dataset_folder = 'C:/Users/jose_/Documents/samsung_ic/datasets/innobrand_dataset_wav'\n",
    "model_name = 'My-Voice'\n",
    "\n",
    "# Configurar path de RVC para importaciones\n",
    "rvc_path = os.path.join(curr_path, 'RVC')\n",
    "print(f\"📂 RVC Path: {rvc_path}\")\n",
    "\n",
    "# Agregar RVC al Python path si no está ya\n",
    "if rvc_path not in sys.path:\n",
    "    sys.path.insert(0, rvc_path)\n",
    "    print(\"✅ RVC path agregado al sistema\")\n",
    "\n",
    "# Cambiar al directorio RVC para imports relativos\n",
    "original_cwd = os.getcwd()\n",
    "print(f\"📂 Directorio original: {original_cwd}\")\n",
    "\n",
    "try:\n",
    "    os.chdir(rvc_path)\n",
    "    print(f\"📂 Cambiado a directorio RVC: {os.getcwd()}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 📦 IMPORTACIÓN DE MÓDULOS RVC / RVC MODULES IMPORT\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Ahora importar la función de preprocesamiento\n",
    "    print(\"📥 Importando función de preprocesamiento...\")\n",
    "    from infer.modules.train.preprocess import preprocess_trainset\n",
    "    print(\"✅ Función preprocess_trainset importada exitosamente\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ⚙️ CONFIGURACIÓN DE PARÁMETROS / PARAMETER CONFIGURATION\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Parámetros del preprocesamiento\n",
    "    sample_rate = 32000      # Frecuencia de muestreo (32kHz recomendado)\n",
    "    num_threads = 2          # Número de hilos para procesamiento paralelo\n",
    "    log_path = f'{curr_path}/RVC/logs/{model_name}'  # Ruta de logs del experimento\n",
    "    use_f0 = False          # Configuración F0 (False = no usar paralelización)\n",
    "    f0_threshold = 3.0      # Umbral de pitch (valor por defecto)\n",
    "    \n",
    "    # Mostrar configuración\n",
    "    print(f\"\\n📋 CONFIGURACIÓN DE PREPROCESAMIENTO:\")\n",
    "    print(f\"   • Dataset de entrada: {dataset_folder}\")\n",
    "    print(f\"   • Modelo: {model_name}\")\n",
    "    print(f\"   • Sample rate: {sample_rate} Hz\")\n",
    "    print(f\"   • Hilos de procesamiento: {num_threads}\")\n",
    "    print(f\"   • Directorio de salida: {log_path}\")\n",
    "    print(f\"   • Uso de F0: {use_f0}\")\n",
    "    print(f\"   • Umbral F0: {f0_threshold}\")\n",
    "    \n",
    "    # Verificar que existe el dataset\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        print(f\"❌ ERROR: No se encuentra el dataset en {dataset_folder}\")\n",
    "        print(\"   Asegúrate de haber ejecutado la celda de conversión MP3 a WAV primero\")\n",
    "    else:\n",
    "        wav_files = [f for f in os.listdir(dataset_folder) if f.lower().endswith('.wav')]\n",
    "        print(f\"✅ Dataset encontrado: {len(wav_files)} archivos WAV\")\n",
    "        \n",
    "        if len(wav_files) == 0:\n",
    "            print(\"⚠️  ADVERTENCIA: No se encontraron archivos WAV en el dataset\")\n",
    "        else:\n",
    "            print(f\"   Primeros archivos: {wav_files[:3]}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 🚀 EJECUCIÓN DEL PREPROCESAMIENTO / PREPROCESSING EXECUTION\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n🚀 Iniciando preprocesamiento del dataset...\")\n",
    "    print(\"Este proceso puede tardar varios minutos dependiendo del tamaño del dataset\")\n",
    "    \n",
    "    # Ejecutar la función preprocess_trainset\n",
    "    try:\n",
    "        preprocess_trainset(\n",
    "            inp_root=dataset_folder,     # Directorio de entrada con archivos WAV\n",
    "            sr=sample_rate,              # Sample rate\n",
    "            n_p=num_threads,             # Número de procesos paralelos\n",
    "            exp_dir=log_path,            # Directorio de experimento (salida)\n",
    "            per=f0_threshold,            # Percentil para F0\n",
    "            noparallel=use_f0            # Si usar paralelización (False = sí usar)\n",
    "        )\n",
    "        print(\"\\n✅ PREPROCESAMIENTO COMPLETADO EXITOSAMENTE!\")\n",
    "        print(f\"📁 Archivos generados en: {log_path}\")\n",
    "        \n",
    "        # Verificar archivos generados\n",
    "        if os.path.exists(log_path):\n",
    "            subdirs = [d for d in os.listdir(log_path) if os.path.isdir(os.path.join(log_path, d))]\n",
    "            print(f\"📂 Subdirectorios creados: {subdirs}\")\n",
    "            \n",
    "            # Verificar contenido de cada subdirectorio\n",
    "            for subdir in subdirs:\n",
    "                subdir_path = os.path.join(log_path, subdir)\n",
    "                files_count = len([f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))])\n",
    "                print(f\"   • {subdir}: {files_count} archivos\")\n",
    "        else:\n",
    "            print(\"⚠️  Directorio de salida no encontrado, pero proceso completó sin errores\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR DURANTE EL PREPROCESAMIENTO:\")\n",
    "        print(f\"   Tipo de error: {type(e).__name__}\")\n",
    "        print(f\"   Mensaje: {str(e)}\")\n",
    "        # Mostrar traceback completo para debugging\n",
    "        import traceback\n",
    "        print(f\"\\n🔍 TRACEBACK COMPLETO:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Restaurar directorio original\n",
    "    os.chdir(original_cwd)\n",
    "    print(f\"\\n📂 Restaurado al directorio original: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracción F0 y características completada exitosamente!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Verificar dependencias antes de continuar\n",
    "# Add RVC to Python path\n",
    "rvc_path = os.path.join(curr_path, 'RVC')\n",
    "if rvc_path not in sys.path:\n",
    "    sys.path.append(rvc_path)\n",
    "\n",
    "# Change to RVC directory for relative paths\n",
    "original_cwd = os.getcwd()\n",
    "os.chdir(rvc_path)\n",
    "\n",
    "try:\n",
    "    # Import the modified extraction functions\n",
    "    print(\"\\nImportando funciones de extracción...\")\n",
    "    from infer.modules.train.extract.extract_f0_print import extract_f0_print\n",
    "    \n",
    "    # Intentar importar fairseq, si falla usar solo F0\n",
    "    try:\n",
    "        from infer.modules.train.extract_feature_print import extract_feature_print\n",
    "        fairseq_available = True\n",
    "        print(\"✓ Funciones de extracción HuBERT disponibles\")\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Error importando HuBERT: {e}\")\n",
    "        print(\"Continuando solo con extracción F0...\")\n",
    "        fairseq_available = False\n",
    "    \n",
    "    f0method = \"pm\"  # Options: [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
    "    exp_dir_path = f\"./logs/{model_name}\"\n",
    "    \n",
    "    print(f\"\\nIniciando extracción usando funciones Python puras...\")\n",
    "    \n",
    "    # Extract F0 features (esto siempre debería funcionar)\n",
    "    print(\"Paso 1: Extrayendo características F0...\")\n",
    "    f0_success = extract_f0_print(\n",
    "        exp_dir=exp_dir_path,\n",
    "        n_p=2,  # Number of processes\n",
    "        f0method=f0method\n",
    "    )\n",
    "    \n",
    "    if f0_success:\n",
    "        print(\"✓ Extracción F0 completada exitosamente!\")\n",
    "        \n",
    "        # Extract HuBERT features (solo si fairseq está disponible)\n",
    "        if fairseq_available:\n",
    "            print(\"Paso 2: Extrayendo características HuBERT...\")\n",
    "            try:\n",
    "                feature_success = extract_feature_print(\n",
    "                    device_arg=\"cuda:0\",\n",
    "                    n_part=1,\n",
    "                    i_part=0,\n",
    "                    exp_dir=exp_dir_path,\n",
    "                    version=\"v2\",\n",
    "                    is_half=True\n",
    "                )\n",
    "                \n",
    "                if feature_success:\n",
    "                    print(\"✓ Extracción HuBERT completada exitosamente!\")\n",
    "                    \n",
    "                    # Check completion\n",
    "                    log_file_path = f'{exp_dir_path}/extract_f0_feature.log'\n",
    "                    try:\n",
    "                        with open(log_file_path, 'r') as f:\n",
    "                            log_content = f.read()\n",
    "                            if 'all-feature-done' in log_content:\n",
    "                                clear_output()\n",
    "                                print(\"✓ Extracción F0 y características completada exitosamente!\")\n",
    "                            else:\n",
    "                                print(\"Proceso completado pero marcador 'all-feature-done' no encontrado\")\n",
    "                    except FileNotFoundError:\n",
    "                        print(\"Advertencia: Archivo de log no encontrado, pero extracción aparenta ser exitosa\")\n",
    "                else:\n",
    "                    print(\"❌ Extracción HuBERT falló\")\n",
    "            except Exception as feature_error:\n",
    "                print(f\"❌ Error en extracción HuBERT: {feature_error}\")\n",
    "                print(\"Continuando solo con F0...\")\n",
    "        else:\n",
    "            print(\"⚠️ Saltando extracción HuBERT (fairseq no disponible)\")\n",
    "            print(\"Solo se completó la extracción F0. Para entrenamiento completo, resuelve los problemas de fairseq.\")\n",
    "    else:\n",
    "        print(\"❌ Extracción F0 falló\")\n",
    "        \n",
    "except ImportError as import_error:\n",
    "    print(f\"❌ Error de importación: {import_error}\")\n",
    "    print(\"Algunas dependencias requeridas aún faltan.\")\n",
    "    print(\"Ejecuta la celda anterior para instalar dependencias.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error durante extracción F0 y características: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Restore original working directory\n",
    "    os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "gSXD8O5aK79w"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fdbbb89f9d497d9541153664a29aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='✅ Índice Completado', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 ÍNDICE COMPLETADO:\n",
      "📁 Archivo: logs/My-Voice/added_IVF1264_Flat_nprobe_1_My-Voice_v2.index\n",
      "📊 Vectores: 49319\n",
      "🔍 Clusters IVF: 1264\n",
      "📐 Dimensiones: 768\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import traceback\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import Button\n",
    "\n",
    "from RVC.configs import config\n",
    "\n",
    "os.chdir(curr_path + '/RVC')\n",
    "\n",
    "def train_index(exp_dir1, version19):\n",
    "    \"\"\"\n",
    "    Construye un índice FAISS para búsqueda rápida de características durante la inferencia.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir1: Nombre del experimento/modelo\n",
    "        version19: Versión del modelo (\"v1\" o \"v2\")\n",
    "    \n",
    "    Returns:\n",
    "        Generator que yield mensajes de progreso\n",
    "    \"\"\"\n",
    "    # Configurar directorios\n",
    "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Seleccionar directorio de características según la versión\n",
    "    # v1 usa características de 256 dimensiones, v2 usa 768 dimensiones\n",
    "    feature_dir = (\n",
    "        \"%s/3_feature256\" % (exp_dir)\n",
    "        if version19 == \"v1\"\n",
    "        else \"%s/3_feature768\" % (exp_dir)\n",
    "    )\n",
    "    \n",
    "    # Verificar que existan las características extraídas\n",
    "    if not os.path.exists(feature_dir):\n",
    "        return \"¡Por favor, realiza primero la extracción de características!\"\n",
    "    \n",
    "    listdir_res = list(os.listdir(feature_dir))\n",
    "    if len(listdir_res) == 0:\n",
    "        return \"¡Por favor, realiza primero la extracción de características!\"\n",
    "    \n",
    "    infos = []  # Lista para almacenar mensajes de progreso\n",
    "    npys = []   # Lista para almacenar vectores de características\n",
    "    \n",
    "    # Cargar todos los archivos .npy de características\n",
    "    print(f\"Cargando {len(listdir_res)} archivos de características...\")\n",
    "    for name in sorted(listdir_res):\n",
    "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
    "        npys.append(phone)\n",
    "    \n",
    "    # Concatenar todas las características en un solo array\n",
    "    big_npy = np.concatenate(npys, 0)\n",
    "    print(f\"Características totales: {big_npy.shape}\")\n",
    "    \n",
    "    # Mezclar aleatoriamente las características para mejor distribución\n",
    "    big_npy_idx = np.arange(big_npy.shape[0])\n",
    "    np.random.shuffle(big_npy_idx)\n",
    "    big_npy = big_npy[big_npy_idx]\n",
    "    \n",
    "    # Si hay más de 200k vectores, aplicar K-means para reducir a 10k centros\n",
    "    # Esto reduce el tamaño del índice y mejora la velocidad de búsqueda\n",
    "    if big_npy.shape[0] > 2e5:\n",
    "        infos.append(\"Aplicando K-means: reduciendo %s vectores a 10k centros.\" % big_npy.shape[0])\n",
    "        yield \"\\n\".join(infos)\n",
    "        try:\n",
    "            # MiniBatchKMeans es más eficiente en memoria que KMeans regular\n",
    "            big_npy = (\n",
    "                MiniBatchKMeans(\n",
    "                    n_clusters=10000,          # Reducir a 10k centros\n",
    "                    verbose=True,              # Mostrar progreso\n",
    "                    batch_size=256 * config.n_cpu,  # Tamaño de lote basado en CPUs\n",
    "                    compute_labels=False,      # No necesitamos las etiquetas\n",
    "                    init=\"random\",             # Inicialización aleatoria\n",
    "                )\n",
    "                .fit(big_npy)\n",
    "                .cluster_centers_             # Solo guardamos los centros\n",
    "            )\n",
    "            print(f\"K-means completado. Nuevas dimensiones: {big_npy.shape}\")\n",
    "        except:\n",
    "            info = traceback.format_exc()\n",
    "            infos.append(f\"Error en K-means: {info}\")\n",
    "            yield \"\\n\".join(infos)\n",
    "\n",
    "    # Guardar las características procesadas\n",
    "    feature_file = \"%s/total_fea.npy\" % exp_dir\n",
    "    np.save(feature_file, big_npy)\n",
    "    print(f\"Características guardadas en: {feature_file}\")\n",
    "    \n",
    "    # Calcular parámetros para el índice FAISS\n",
    "    # n_ivf: número de clusters invertidos (afecta velocidad vs precisión)\n",
    "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
    "    infos.append(\"Forma de características: %s, Clusters IVF: %s\" % (big_npy.shape, n_ivf))\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    # Crear índice FAISS\n",
    "    # IVF = Inverted File (búsqueda aproximada rápida)\n",
    "    # Flat = búsqueda exacta dentro de cada cluster\n",
    "    dimension = 256 if version19 == \"v1\" else 768\n",
    "    index = faiss.index_factory(dimension, \"IVF%s,Flat\" % n_ivf)\n",
    "    \n",
    "    infos.append(\"Entrenando índice FAISS...\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    # Configurar parámetros del índice\n",
    "    index_ivf = faiss.extract_index_ivf(index)\n",
    "    index_ivf.nprobe = 1  # Número de clusters a buscar (1 = más rápido)\n",
    "    \n",
    "    # Entrenar el índice con las características\n",
    "    print(\"Entrenando índice FAISS...\")\n",
    "    index.train(big_npy)\n",
    "    \n",
    "    # Guardar índice entrenado (sin datos)\n",
    "    trained_index_path = (\n",
    "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "    faiss.write_index(index, trained_index_path)\n",
    "    print(f\"Índice entrenado guardado: {trained_index_path}\")\n",
    "\n",
    "    infos.append(\"Agregando vectores al índice...\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    # Agregar vectores al índice en lotes para eficiencia de memoria\n",
    "    batch_size_add = 8192\n",
    "    total_vectors = big_npy.shape[0]\n",
    "    \n",
    "    print(f\"Agregando {total_vectors} vectores en lotes de {batch_size_add}...\")\n",
    "    for i in range(0, total_vectors, batch_size_add):\n",
    "        batch_end = min(i + batch_size_add, total_vectors)\n",
    "        index.add(big_npy[i:batch_end])\n",
    "        if i % (batch_size_add * 4) == 0:  # Progreso cada 4 lotes\n",
    "            print(f\"Progreso: {i}/{total_vectors} vectores agregados\")\n",
    "    \n",
    "    # Guardar índice completo (con datos)\n",
    "    final_index_path = (\n",
    "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "    faiss.write_index(index, final_index_path)\n",
    "    \n",
    "    # Mensaje de éxito\n",
    "    success_msg = (\n",
    "        \"✅ Índice construido exitosamente: added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "    infos.append(success_msg)\n",
    "    yield \"\\n\".join(infos)\n",
    "    \n",
    "    print(f\"\\n🎉 ÍNDICE COMPLETADO:\")\n",
    "    print(f\"📁 Archivo: {final_index_path}\")\n",
    "    print(f\"📊 Vectores: {total_vectors}\")\n",
    "    print(f\"🔍 Clusters IVF: {n_ivf}\")\n",
    "    print(f\"📐 Dimensiones: {dimension}\")\n",
    "\n",
    "# Ejecutar construcción del índice\n",
    "print(\"🚀 Iniciando construcción del índice FAISS...\")\n",
    "print(\"Este proceso puede tomar varios minutos dependiendo del tamaño del dataset.\")\n",
    "\n",
    "training_log = train_index(model_name, 'v2')\n",
    "\n",
    "for line in training_log:\n",
    "    print(line)\n",
    "    if 'adding' in line.lower() or 'agregando' in line.lower():\n",
    "        clear_output()\n",
    "        display(Button(description=\"✅ Índice Completado\", button_style=\"success\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 🖥️ DETECCIÓN Y CONFIGURACIÓN AUTOMÁTICA DE GPU / AUTO GPU DETECTION & CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"🔍 Detectando configuración de GPU...\")\n",
    "\n",
    "# Verificar disponibilidad de CUDA y GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB\n",
    "    \n",
    "    print(f\"✅ GPU detectada: {gpu_name}\")\n",
    "    print(f\"📊 Memoria GPU: {gpu_memory:.1f} GB\")\n",
    "    print(f\"🔢 Número de GPUs: {gpu_count}\")\n",
    "    \n",
    "    # Configurar GPU según hardware disponible\n",
    "    if gpu_count == 1:\n",
    "        gpus = \"0\"  # Una sola GPU\n",
    "        batch_size = 4 if gpu_memory >= 8 else 2  # Ajustar batch según memoria\n",
    "    else:\n",
    "        gpus = \",\".join([str(i) for i in range(gpu_count)])  # Multi-GPU\n",
    "        batch_size = 6 if gpu_memory >= 8 else 4\n",
    "    \n",
    "    print(f\"⚙️ Configuración GPU: {gpus}\")\n",
    "    print(f\"📦 Batch Size ajustado: {batch_size}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No se detectó GPU CUDA disponible\")\n",
    "    print(\"⚠️ ADVERTENCIA: RVC requiere GPU para entrenamiento eficiente\")\n",
    "    print(\"💡 Considera usar Google Colab o instalar CUDA\")\n",
    "    \n",
    "    # Configuración fallback para CPU (no recomendado para entrenamiento)\n",
    "    gpus = \"0\"  # Forzar a intentar GPU 0\n",
    "    batch_size = 1\n",
    "    \n",
    "    print(f\"🔧 Usando configuración básica: GPU={gpus}, Batch={batch_size}\")\n",
    "\n",
    "# Actualizar variables globales\n",
    "batch_size = batch_size  # Sobrescribir batch_size anterior si existía\n",
    "\n",
    "print(f\"✅ Configuración GPU completada: {gpus}\")\n",
    "print(f\"📋 Batch size final: {batch_size}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 VERIFICACIÓN FINAL DE CONFIGURACIÓN SINGLE-GPU\n",
      "============================================================\n",
      "1. Variables de entorno:\n",
      "   ✅ CUDA_VISIBLE_DEVICES: 0\n",
      "   ✅ WORLD_SIZE: 1\n",
      "   ✅ RANK: 0\n",
      "   ✅ LOCAL_RANK: 0\n",
      "   ✅ NCCL_P2P_DISABLE: 1\n",
      "   ✅ NCCL_IB_DISABLE: 1\n",
      "\n",
      "2. Configuración PyTorch:\n",
      "   ✅ GPU activa: 0\n",
      "   ✅ Nombre: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "   ✅ Memoria: 6.0 GB\n",
      "   ✅ CuDNN: True\n",
      "   📊 Memoria usada: 0.00 GB\n",
      "   📊 Memoria reservada: 0.00 GB\n",
      "   📊 Memoria libre: 6.00 GB\n",
      "   ✅ Memoria suficiente para entrenamiento\n",
      "\n",
      "3. Configuración RVC:\n",
      "   📋 model_name: My-Voice\n",
      "   📋 gpu_config: 0\n",
      "   📋 batch_size: 1\n",
      "   📋 sample_rate: 32k\n",
      "   📋 epochs: 300\n",
      "   📋 cache: False\n",
      "   📋 OV2: False\n",
      "\n",
      "4. Recomendaciones finales para RTX 4050:\n",
      "   🎯 Configuración ÓPTIMA detectada:\n",
      "   ✅ Batch size: 1 (apropiado)\n",
      "   ✅ Caché GPU: False (correcto)\n",
      "   ✅ GPU config: 0 (correcto)\n",
      "\n",
      "🎉 VERIFICACIÓN COMPLETADA\n",
      "✅ Sistema listo para entrenamiento single-GPU en RTX 4050\n",
      "💡 El entrenamiento debería ejecutarse sin errores de distributed training\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ✅ VERIFICACIÓN FINAL SINGLE-GPU PARA RTX 4050 / FINAL SINGLE-GPU CHECK\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"🔍 VERIFICACIÓN FINAL DE CONFIGURACIÓN SINGLE-GPU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. VERIFICAR VARIABLES DE ENTORNO\n",
    "print(\"1. Variables de entorno:\")\n",
    "env_vars = [\n",
    "    'CUDA_VISIBLE_DEVICES', 'WORLD_SIZE', 'RANK', 'LOCAL_RANK',\n",
    "    'NCCL_P2P_DISABLE', 'NCCL_IB_DISABLE'\n",
    "]\n",
    "\n",
    "for var in env_vars:\n",
    "    value = os.environ.get(var, 'No configurado')\n",
    "    status = \"✅\" if var in os.environ else \"⚠️\"\n",
    "    print(f\"   {status} {var}: {value}\")\n",
    "\n",
    "# 2. VERIFICAR PYTORCH Y GPU\n",
    "print(\"\\n2. Configuración PyTorch:\")\n",
    "if torch.cuda.is_available():\n",
    "    current_device = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    device_memory = torch.cuda.get_device_properties(current_device).total_memory / 1024**3\n",
    "    \n",
    "    print(f\"   ✅ GPU activa: {current_device}\")\n",
    "    print(f\"   ✅ Nombre: {device_name}\")\n",
    "    print(f\"   ✅ Memoria: {device_memory:.1f} GB\")\n",
    "    print(f\"   ✅ CuDNN: {torch.backends.cudnn.is_available()}\")\n",
    "    \n",
    "    # Test de memoria disponible\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        memory_cached = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        memory_free = device_memory - memory_cached\n",
    "        \n",
    "        print(f\"   📊 Memoria usada: {memory_allocated:.2f} GB\")\n",
    "        print(f\"   📊 Memoria reservada: {memory_cached:.2f} GB\")\n",
    "        print(f\"   📊 Memoria libre: {memory_free:.2f} GB\")\n",
    "        \n",
    "        if memory_free >= 4.0:\n",
    "            print(\"   ✅ Memoria suficiente para entrenamiento\")\n",
    "        else:\n",
    "            print(\"   ⚠️ Memoria limitada - usar batch_size=1\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Error verificando memoria: {e}\")\n",
    "else:\n",
    "    print(\"   ❌ GPU no disponible\")\n",
    "\n",
    "# 3. VERIFICAR CONFIGURACIÓN RVC\n",
    "print(\"\\n3. Configuración RVC:\")\n",
    "config_items = [\n",
    "    ('model_name', globals().get('model_name', 'No definido')),\n",
    "    ('gpu_config', globals().get('gpu_config', 'No definido')),\n",
    "    ('batch_size', globals().get('batch_size', 'No definido')),\n",
    "    ('sample_rate', globals().get('sample_rate', 'No definido')),\n",
    "    ('epochs', globals().get('epochs', 'No definido')),\n",
    "    ('cache', globals().get('cache', 'No definido')),\n",
    "    ('OV2', globals().get('OV2', 'No definido')),\n",
    "]\n",
    "\n",
    "for name, value in config_items:\n",
    "    print(f\"   📋 {name}: {value}\")\n",
    "\n",
    "# 4. RECOMENDACIONES FINALES\n",
    "print(\"\\n4. Recomendaciones finales para RTX 4050:\")\n",
    "print(\"   🎯 Configuración ÓPTIMA detectada:\")\n",
    "\n",
    "# Verificar y ajustar configuración final\n",
    "final_batch_size = globals().get('batch_size', 2)\n",
    "final_cache = globals().get('cache', False)\n",
    "final_gpu_config = globals().get('gpu_config', '0')\n",
    "\n",
    "if final_batch_size > 4:\n",
    "    print(\"   ⚠️ Batch size muy alto, se recomienda ≤2 para RTX 4050\")\n",
    "    final_batch_size = 2\n",
    "else:\n",
    "    print(f\"   ✅ Batch size: {final_batch_size} (apropiado)\")\n",
    "\n",
    "if final_cache:\n",
    "    print(\"   ⚠️ Caché habilitado puede causar problemas de memoria\")\n",
    "    final_cache = False\n",
    "else:\n",
    "    print(f\"   ✅ Caché GPU: {final_cache} (correcto)\")\n",
    "\n",
    "if final_gpu_config != \"0\":\n",
    "    print(\"   ⚠️ GPU config debe ser '0' para single-GPU\")\n",
    "    final_gpu_config = \"0\"\n",
    "else:\n",
    "    print(f\"   ✅ GPU config: {final_gpu_config} (correcto)\")\n",
    "\n",
    "# Actualizar variables globales con valores corregidos\n",
    "globals()['batch_size'] = final_batch_size\n",
    "globals()['cache'] = final_cache\n",
    "globals()['gpu_config'] = final_gpu_config\n",
    "\n",
    "print(\"\\n🎉 VERIFICACIÓN COMPLETADA\")\n",
    "print(\"✅ Sistema listo para entrenamiento single-GPU en RTX 4050\")\n",
    "print(\"💡 El entrenamiento debería ejecutarse sin errores de distributed training\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "id": "ZsfjOgi8LKYM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 CONFIGURANDO SINGLE-GPU PARA RTX 4050 LAPTOP\n",
      "============================================================\n",
      "✅ Variables de entorno configuradas para single-GPU\n",
      "🖥️  GPU detectada: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "💾 Memoria GPU: 6.0 GB\n",
      "🔢 GPUs disponibles: 1 (usando solo GPU 0)\n",
      "⚙️  Configuración GPU: 0\n",
      "📦 Batch Size optimizado: 1\n",
      "✅ Test single-GPU exitoso\n",
      "💾 Caché GPU: False (deshabilitado para ahorrar VRAM)\n",
      "🔄 Mixed Precision: True (FP16 para ahorrar memoria)\n",
      "🚫 Distributed Training: False (deshabilitado)\n",
      "============================================================\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8888 (pid 16952), started 8 days, 0:10:41 ago. (Use '!kill 16952' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3d219d91993144e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3d219d91993144e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 8888;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INICIANDO ENTRENAMIENTO SINGLE-GPU OPTIMIZADO PARA RTX 4050...\n",
      "======================================================================\n",
      "📋 CONFIGURACIÓN FINAL SINGLE-GPU:\n",
      "   • Modelo: My-Voice\n",
      "   • Sample Rate: 32k\n",
      "   • Epochs: 300\n",
      "   • Batch Size: 1 (optimizado para 6GB VRAM)\n",
      "   • GPU Config: 0 (solo GPU 0)\n",
      "   • Guardar cada: 25 epochs\n",
      "   • Usar F0: Sí (pitch tracking habilitado)\n",
      "   • Versión: v2 (recomendado)\n",
      "   • Modelos OV2: No (False recomendado para RTX 4050)\n",
      "   • Caché GPU: False (deshabilitado para ahorrar VRAM)\n",
      "   • Mixed Precision: True (FP16 para eficiencia)\n",
      "   • Distributed: False (single-GPU forzado)\n",
      "======================================================================\n",
      "🔍 Verificación final de configuración single-GPU:\n",
      "✅ GPU Config correcta: solo GPU 0\n",
      "✅ Batch Size seguro para RTX 4050: 1\n",
      "✅ Caché GPU deshabilitado (correcto para 6GB VRAM)\n",
      "======================================================================\n",
      "Write filelist done\n",
      "Use gpus: 0\n",
      "ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': 'assets/pretrained_v2/f0G32k.pth', 'pretrainD': 'assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 315, in _bootstrap\n",
      "self.run()\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 108, in run\n",
      "self._target(*self._args, **self._kwargs)\n",
      "File \"C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\\infer\\modules\\train\\train.py\", line 145, in run\n",
      "dist.init_process_group(\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 79, in wrapper\n",
      "return func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 93, in wrapper\n",
      "func_return = func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1361, in init_process_group\n",
      "store, rank, world_size = next(rendezvous_iterator)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 258, in _env_rendezvous_handler\n",
      "store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 185, in _create_c10d_store\n",
      "return TCPStore(\n",
      "RuntimeError: use_libuv was requested but PyTorch was build without libuv support\n",
      "INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': 'assets/pretrained_v2/f0G32k.pth', 'pretrainD': 'assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 315, in _bootstrap\n",
      "self.run()\n",
      "File \"C:\\Users\\jose_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\process.py\", line 108, in run\n",
      "self._target(*self._args, **self._kwargs)\n",
      "File \"C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\\infer\\modules\\train\\train.py\", line 145, in run\n",
      "dist.init_process_group(\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 79, in wrapper\n",
      "return func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\c10d_logger.py\", line 93, in wrapper\n",
      "func_return = func(*args, **kwargs)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1361, in init_process_group\n",
      "store, rank, world_size = next(rendezvous_iterator)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 258, in _env_rendezvous_handler\n",
      "store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n",
      "File \"c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\lib\\site-packages\\torch\\distributed\\rendezvous.py\", line 185, in _create_c10d_store\n",
      "return TCPStore(\n",
      "RuntimeError: use_libuv was requested but PyTorch was build without libuv support\n",
      "\n",
      "🎉 RESULTADO DEL ENTRENAMIENTO:\n",
      "======================================================================\n",
      "Entrenamiento finalizado, puede revisar los logs de entrenamiento en la consola o en train.log en la carpeta del experimento\n",
      "======================================================================\n",
      "\n",
      "📋 INFORMACIÓN POST-ENTRENAMIENTO:\n",
      "📁 Archivos generados en: ./logs/My-Voice/\n",
      "📊 Monitoreo TensorBoard: http://localhost:8888\n",
      "💾 Checkpoints guardados cada 25 epochs\n",
      "🎯 Modelo final: ./logs/My-Voice/G_300.pth\n",
      "🎵 Para inferencia, usa el archivo .pth generado\n",
      "======================================================================\n",
      "\n",
      "🎉 RESULTADO DEL ENTRENAMIENTO:\n",
      "======================================================================\n",
      "Entrenamiento finalizado, puede revisar los logs de entrenamiento en la consola o en train.log en la carpeta del experimento\n",
      "======================================================================\n",
      "\n",
      "📋 INFORMACIÓN POST-ENTRENAMIENTO:\n",
      "📁 Archivos generados en: ./logs/My-Voice/\n",
      "📊 Monitoreo TensorBoard: http://localhost:8888\n",
      "💾 Checkpoints guardados cada 25 epochs\n",
      "🎯 Modelo final: ./logs/My-Voice/G_300.pth\n",
      "🎵 Para inferencia, usa el archivo .pth generado\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 🎓 ENTRENAMIENTO DE MODELO RVC / RVC MODEL TRAINING\n",
    "# =============================================================================\n",
    "# Este código implementa el entrenamiento completo de un modelo de conversión de voz\n",
    "# usando la arquitectura RVC (Retrieval-based Voice Conversion)\n",
    "\n",
    "#@title  **TRAIN YOUR MODEL** - You can also resume training here!\n",
    "\n",
    "# =============================================================================\n",
    "# 📦 IMPORTACIONES NECESARIAS / REQUIRED IMPORTS\n",
    "# =============================================================================\n",
    "from random import shuffle      # Para mezclar datos aleatoriamente\n",
    "import json                    # Para manejar archivos de configuración JSON\n",
    "import os                      # Para operaciones del sistema de archivos\n",
    "import pathlib                 # Para manejo moderno de rutas de archivos\n",
    "from subprocess import Popen, PIPE, STDOUT  # Para ejecutar procesos externos\n",
    "import torch                   # Para verificación de GPU\n",
    "\n",
    "now_dir = os.getcwd()  # Obtener directorio actual de trabajo\n",
    "\n",
    "# =============================================================================\n",
    "# ⚙️ CONFIGURACIÓN DE PARÁMETROS DE ENTRENAMIENTO / TRAINING PARAMETERS CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "# 🔄 Parámetros principales de entrenamiento\n",
    "# model_name = 'My-Voice'  # Nombre del modelo (definido en celdas anteriores)\n",
    "\n",
    "# 💾 Frecuencia de guardado y duración del entrenamiento\n",
    "save_frequency = 25    # @param {type:\"slider\", min:5, max:50, step:5}\n",
    "                      # Guardar checkpoint cada 25 epochs\n",
    "epochs = 300          # @param {type:\"slider\", min:10, max:2000, step:10} Se pueden usar 500\n",
    "                      # Número total de epochs de entrenamiento\n",
    "\n",
    "# 🚀 Configuraciones avanzadas\n",
    "OV2 = False           # @param {type:\"boolean\"} \n",
    "                     # Usar modelo OV2 Super (versión mejorada con mejor calidad)\n",
    "\n",
    "open_tensorboard = True  # @param{type:\"boolean\"}\n",
    "                        # Abrir TensorBoard para monitoreo en tiempo real\n",
    "\n",
    "# =============================================================================\n",
    "# 🖥️ CONFIGURACIÓN FORZADA SINGLE-GPU PARA RTX 4050 / FORCED SINGLE-GPU CONFIG\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# FORZAR CONFIGURACIÓN SINGLE-GPU para evitar errores distributed training\n",
    "print(\"🔧 CONFIGURANDO SINGLE-GPU PARA RTX 4050 LAPTOP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. CONFIGURAR VARIABLES DE ENTORNO para single-GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'        # Solo GPU 0 visible\n",
    "os.environ['WORLD_SIZE'] = '1'                  # Un solo proceso\n",
    "os.environ['RANK'] = '0'                        # Rank principal\n",
    "os.environ['LOCAL_RANK'] = '0'                  # Rank local 0\n",
    "os.environ['MASTER_ADDR'] = 'localhost'         # Dirección local\n",
    "os.environ['MASTER_PORT'] = '12355'             # Puerto libre\n",
    "\n",
    "# 2. DESHABILITAR backends distribuidos problemáticos\n",
    "os.environ['NCCL_P2P_DISABLE'] = '1'           # Deshabilitar P2P\n",
    "os.environ['NCCL_IB_DISABLE'] = '1'            # Deshabilitar InfiniBand\n",
    "\n",
    "print(\"✅ Variables de entorno configuradas para single-GPU\")\n",
    "\n",
    "# 3. CONFIGURAR PyTorch para single-GPU\n",
    "if torch.cuda.is_available():\n",
    "    # Forzar uso de GPU 0 únicamente\n",
    "    torch.cuda.set_device(0)\n",
    "    \n",
    "    # Configuración optimizada para RTX 4050\n",
    "    torch.backends.cudnn.benchmark = False      # Más estable para batch pequeño\n",
    "    torch.backends.cudnn.deterministic = True   # Reproducible\n",
    "    \n",
    "    # Obtener información de la GPU\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    \n",
    "    # CONFIGURACIÓN ESPECÍFICA PARA RTX 4050 (6GB VRAM)\n",
    "    gpu_config = \"0\"                            # Solo GPU 0\n",
    "    \n",
    "    # Batch size optimizado para 6GB VRAM\n",
    "    if gpu_memory >= 8:\n",
    "        batch_size = 4                          # Para GPUs con >8GB\n",
    "    elif gpu_memory >= 6:\n",
    "        batch_size = 2                          # Para RTX 4050 (6GB)\n",
    "    else:\n",
    "        batch_size = 1                          # Para GPUs con <6GB\n",
    "    \n",
    "    print(f\"🖥️  GPU detectada: {gpu_name}\")\n",
    "    print(f\"💾 Memoria GPU: {gpu_memory:.1f} GB\")\n",
    "    print(f\"🔢 GPUs disponibles: {gpu_count} (usando solo GPU 0)\")\n",
    "    print(f\"⚙️  Configuración GPU: {gpu_config}\")\n",
    "    print(f\"📦 Batch Size optimizado: {batch_size}\")\n",
    "    \n",
    "    # Test de funcionamiento single-GPU\n",
    "    try:\n",
    "        test_tensor = torch.randn(2, 100).cuda()\n",
    "        result = test_tensor * 2\n",
    "        print(\"✅ Test single-GPU exitoso\")\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en test GPU: {e}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ ADVERTENCIA: No se detectó GPU CUDA\")\n",
    "    print(\"💡 Para RTX 4050, asegúrate de:\")\n",
    "    print(\"   1. Tener drivers NVIDIA actualizados\")\n",
    "    print(\"   2. PyTorch con CUDA instalado:\")\n",
    "    print(\"      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    \n",
    "    # Configuración fallback\n",
    "    gpu_config = \"0\"\n",
    "    batch_size = 1\n",
    "    print(f\"🔧 Usando configuración fallback...\")\n",
    "\n",
    "# 4. CONFIGURACIONES ADICIONALES para RTX 4050\n",
    "cache = False                                   # No usar caché GPU (ahorra VRAM)\n",
    "mixed_precision = True                          # Usar FP16 (reduce memoria 50%)\n",
    "use_distributed = False                         # NUNCA usar entrenamiento distribuido\n",
    "\n",
    "print(f\"💾 Caché GPU: {cache} (deshabilitado para ahorrar VRAM)\")\n",
    "print(f\"🔄 Mixed Precision: {mixed_precision} (FP16 para ahorrar memoria)\")\n",
    "print(f\"🚫 Distributed Training: {use_distributed} (deshabilitado)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 🎵 Configuración de audio\n",
    "sample_rate = '32k'  # Frecuencia de muestreo (32kHz es óptimo para la mayoría de casos)\n",
    "\n",
    "# 🤖 Selección automática de modelos preentrenados según configuración\n",
    "if OV2:\n",
    "    # Modelos OV2 Super - versión mejorada con mejor calidad de audio\n",
    "    G_file = f'assets/pretrained_v2/f0Ov2Super{sample_rate}G.pth'  # Generador\n",
    "    D_file = f'assets/pretrained_v2/f0Ov2Super{sample_rate}D.pth'  # Discriminador\n",
    "else:\n",
    "    # Modelos estándar v2\n",
    "    G_file = f'assets/pretrained_v2/f0G{sample_rate}.pth'\n",
    "    D_file = f'assets/pretrained_v2/f0D{sample_rate}.pth'\n",
    "\n",
    "# =============================================================================\n",
    "# 🏗️ FUNCIÓN PRINCIPAL DE ENTRENAMIENTO / MAIN TRAINING FUNCTION\n",
    "# =============================================================================\n",
    "def click_train(\n",
    "    exp_dir1,           # Nombre del experimento/modelo\n",
    "    sr2,                # Sample rate (frecuencia de muestreo)\n",
    "    if_f0_3,           # Si usar información F0 (pitch/tono)\n",
    "    spk_id5,           # ID del hablante (0 para un solo hablante)\n",
    "    save_epoch10,      # Frecuencia de guardado de checkpoints\n",
    "    total_epoch11,     # Número total de epochs\n",
    "    batch_size12,      # Tamaño del batch/lote\n",
    "    if_save_latest13,  # Si guardar siempre el modelo más reciente\n",
    "    pretrained_G14,    # Ruta del generador preentrenado\n",
    "    pretrained_D15,    # Ruta del discriminador preentrenado\n",
    "    gpus16,           # IDs de GPUs a usar (0 = primera GPU)\n",
    "    if_cache_gpu17,   # Si usar caché en GPU para acelerar entrenamiento\n",
    "    if_save_every_weights18,  # Si guardar pesos en cada checkpoint\n",
    "    version19,        # Versión del modelo (\"v1\" o \"v2\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el entrenamiento del modelo RVC.\n",
    "    \n",
    "    Proceso:\n",
    "    1. Generar lista de archivos de entrenamiento (filelist)\n",
    "    2. Configurar parámetros del modelo\n",
    "    3. Ejecutar script de entrenamiento\n",
    "    4. Monitorear progreso en tiempo real\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 📁 CONFIGURACIÓN DE DIRECTORIOS / DIRECTORY SETUP\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Crear directorio del experimento\n",
    "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Definir rutas de directorios de datos\n",
    "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)      # Audio original (ground truth)\n",
    "    \n",
    "    # Seleccionar directorio de características según versión del modelo\n",
    "    # v1 usa 256 dimensiones, v2 usa 768 dimensiones\n",
    "    feature_dir = (\n",
    "        \"%s/3_feature256\" % (exp_dir)  # Para modelo v1\n",
    "        if version19 == \"v1\"\n",
    "        else \"%s/3_feature768\" % (exp_dir)  # Para modelo v2\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 🎯 IDENTIFICACIÓN DE ARCHIVOS VÁLIDOS / VALID FILES IDENTIFICATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    if if_f0_3:  # Si se usa información de pitch/tono\n",
    "        # Directorios adicionales para información F0\n",
    "        f0_dir = \"%s/2a_f0\" % (exp_dir)        # Archivos F0 básicos\n",
    "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)  # Archivos F0 NSF (mejorados)\n",
    "        \n",
    "        # Encontrar archivos que tienen TODOS los componentes necesarios\n",
    "        # Usando intersección de conjuntos para asegurar completitud\n",
    "        names = (\n",
    "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) &\n",
    "            set([name.split(\".\")[0] for name in os.listdir(feature_dir)]) &\n",
    "            set([name.split(\".\")[0] for name in os.listdir(f0_dir)]) &\n",
    "            set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
    "        )\n",
    "    else:  # Sin información de pitch\n",
    "        # Solo necesitamos audio original y características\n",
    "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
    "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
    "        )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 📝 GENERACIÓN DE LISTA DE ENTRENAMIENTO / TRAINING LIST GENERATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    opt = []  # Lista que contendrá todas las entradas de entrenamiento\n",
    "    \n",
    "    # Crear entrada para cada archivo válido\n",
    "    for name in names:\n",
    "        if if_f0_3:  # Con información de pitch\n",
    "            # Formato: audio|características|f0|f0nsf|speaker_id\n",
    "            # Cada \"|\" separa un componente diferente del entrenamiento\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
    "                % (\n",
    "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,    # Audio original\n",
    "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,    # Características HuBERT\n",
    "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,         # Información F0\n",
    "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,      # Información F0 NSF\n",
    "                    spk_id5,                                     # ID del hablante\n",
    "                )\n",
    "            )\n",
    "        else:  # Sin información de pitch\n",
    "            # Formato simplificado: audio|características|speaker_id\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
    "                % (\n",
    "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,\n",
    "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"), name,\n",
    "                    spk_id5,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 🔇 AGREGAR ARCHIVOS \"MUTE\" PARA ESTABILIDAD / ADD MUTE FILES FOR STABILITY\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Determinar dimensión de características según versión\n",
    "    fea_dim = 256 if version19 == \"v1\" else 768\n",
    "    \n",
    "    # Agregar archivos \"mute\" (silencio) para estabilizar el entrenamiento\n",
    "    # Estos archivos ayudan a que el modelo no se sobreajuste\n",
    "    if if_f0_3:\n",
    "        for _ in range(2):  # Agregar 2 entradas mute\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
    "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
    "            )\n",
    "    else:\n",
    "        for _ in range(2):\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
    "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
    "            )\n",
    "    \n",
    "    # Mezclar la lista para entrenamiento aleatorio (mejora la convergencia)\n",
    "    shuffle(opt)\n",
    "    \n",
    "    # Guardar lista de archivos de entrenamiento\n",
    "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
    "        f.write(\"\\n\".join(opt))\n",
    "\n",
    "    # =========================================================================\n",
    "    # 📊 INFORMACIÓN DE CONFIGURACIÓN / CONFIGURATION INFO\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Mostrar información de la configuración actual\n",
    "    print(\"Write filelist done\")\n",
    "    print(\"Use gpus:\", str(gpus16))\n",
    "    if pretrained_G14 == \"\":\n",
    "        print(\"No pretrained Generator\")\n",
    "    if pretrained_D15 == \"\":\n",
    "        print(\"No pretrained Discriminator\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # ⚙️ CONFIGURACIÓN DEL MODELO / MODEL CONFIGURATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Seleccionar archivo de configuración según versión y sample rate\n",
    "    if version19 == \"v1\" or sr2 == \"40k\":\n",
    "        config_path = \"configs/v1/%s.json\" % sr2\n",
    "    else:\n",
    "        config_path = \"configs/v2/%s.json\" % sr2\n",
    "    \n",
    "    # Copiar configuración al directorio del experimento\n",
    "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
    "    if not pathlib.Path(config_save_path).exists():\n",
    "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            with open(config_path, \"r\") as config_file:\n",
    "                config_data = json.load(config_file)\n",
    "                json.dump(\n",
    "                    config_data,\n",
    "                    f,\n",
    "                    ensure_ascii=False,\n",
    "                    indent=4,\n",
    "                    sort_keys=True,\n",
    "                )\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 🚀 CONSTRUCCIÓN Y EJECUCIÓN DEL COMANDO DE ENTRENAMIENTO / TRAINING COMMAND\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Construir comando de entrenamiento con todos los parámetros\n",
    "    cmd = (\n",
    "        'python infer/modules/train/train.py '  # Script principal de entrenamiento\n",
    "        '-e \"%s\" '      # Directorio del experimento\n",
    "        '-sr %s '       # Sample rate\n",
    "        '-f0 %s '       # Usar F0 (1=sí, 0=no)\n",
    "        '-bs %s '       # Batch size\n",
    "        '-g %s '        # GPUs a usar\n",
    "        '-te %s '       # Total epochs\n",
    "        '-se %s '       # Save epochs (frecuencia de guardado)\n",
    "        '%s '           # Generador preentrenado (opcional)\n",
    "        '%s '           # Discriminador preentrenado (opcional)\n",
    "        '-l %s '        # Save latest (guardar último modelo)\n",
    "        '-c %s '        # Cache GPU\n",
    "        '-sw %s '       # Save weights (guardar pesos)\n",
    "        '-v %s'         # Versión del modelo\n",
    "        % (\n",
    "            exp_dir1,\n",
    "            sr2,\n",
    "            1 if if_f0_3 else 0,\n",
    "            batch_size12,\n",
    "            gpus16,\n",
    "            total_epoch11,\n",
    "            save_epoch10,\n",
    "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
    "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
    "            1 if if_save_latest13 == True else 0,\n",
    "            1 if if_cache_gpu17 == True else 0,\n",
    "            1 if if_save_every_weights18 == True else 0,\n",
    "            version19,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 📺 EJECUCIÓN CON MONITOREO EN TIEMPO REAL / REAL-TIME MONITORING\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Ejecutar comando con captura de salida en tiempo real\n",
    "    # PIPE permite capturar tanto stdout como stderr\n",
    "    p = Popen(cmd, shell=True, cwd=now_dir, \n",
    "              stdout=PIPE, stderr=STDOUT, \n",
    "              bufsize=1, universal_newlines=True)\n",
    "\n",
    "    # Mostrar salida del entrenamiento en tiempo real\n",
    "    # Esto permite ver el progreso, pérdidas, y posibles errores\n",
    "    for line in p.stdout:\n",
    "        print(line.strip())\n",
    "\n",
    "    # Esperar a que termine el proceso de entrenamiento\n",
    "    p.wait()\n",
    "    \n",
    "    # Mensaje de finalización (traducido al español)\n",
    "    return \"Entrenamiento finalizado, puede revisar los logs de entrenamiento en la consola o en train.log en la carpeta del experimento\"\n",
    "\n",
    "# =============================================================================\n",
    "# 📊 CONFIGURACIÓN DE TENSORBOARD PARA MONITOREO / TENSORBOARD MONITORING SETUP\n",
    "# =============================================================================\n",
    "\n",
    "if open_tensorboard:\n",
    "    # TensorBoard permite visualizar:\n",
    "    # - Pérdidas del generador y discriminador en tiempo real\n",
    "    # - Espectrogramas de audio original vs generado\n",
    "    # - Métricas de entrenamiento y progreso\n",
    "    # - Gráficas de learning rate y gradientes\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir ./logs --port=8888\n",
    "\n",
    "# =============================================================================\n",
    "# 🎯 EJECUCIÓN DEL ENTRENAMIENTO SINGLE-GPU / SINGLE-GPU TRAINING EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# CONFIGURACIÓN FINAL OPTIMIZADA PARA RTX 4050 SINGLE-GPU\n",
    "print(\"🚀 INICIANDO ENTRENAMIENTO SINGLE-GPU OPTIMIZADO PARA RTX 4050...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verificar que las variables estén definidas\n",
    "if \"cache\" not in locals():\n",
    "    cache = False  # Deshabilitado para RTX 4050 (ahorra VRAM)\n",
    "\n",
    "if \"mixed_precision\" not in locals():\n",
    "    mixed_precision = True  # Habilitar FP16 para ahorrar memoria\n",
    "\n",
    "print(f\"📋 CONFIGURACIÓN FINAL SINGLE-GPU:\")\n",
    "print(f\"   • Modelo: {model_name}\")\n",
    "print(f\"   • Sample Rate: {sample_rate}\")\n",
    "print(f\"   • Epochs: {epochs}\")\n",
    "print(f\"   • Batch Size: {batch_size} (optimizado para 6GB VRAM)\")\n",
    "print(f\"   • GPU Config: {gpu_config} (solo GPU 0)\")\n",
    "print(f\"   • Guardar cada: {save_frequency} epochs\")\n",
    "print(f\"   • Usar F0: Sí (pitch tracking habilitado)\")\n",
    "print(f\"   • Versión: v2 (recomendado)\")\n",
    "print(f\"   • Modelos OV2: {'Sí' if OV2 else 'No'} (False recomendado para RTX 4050)\")\n",
    "print(f\"   • Caché GPU: {cache} (deshabilitado para ahorrar VRAM)\")\n",
    "print(f\"   • Mixed Precision: {mixed_precision} (FP16 para eficiencia)\")\n",
    "print(f\"   • Distributed: False (single-GPU forzado)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# VERIFICACIÓN FINAL DE CONFIGURACIÓN SINGLE-GPU\n",
    "print(\"🔍 Verificación final de configuración single-GPU:\")\n",
    "if gpu_config == \"0\":\n",
    "    print(\"✅ GPU Config correcta: solo GPU 0\")\n",
    "else:\n",
    "    print(\"⚠️ Corrigiendo GPU Config a single-GPU...\")\n",
    "    gpu_config = \"0\"\n",
    "\n",
    "if batch_size <= 4:\n",
    "    print(f\"✅ Batch Size seguro para RTX 4050: {batch_size}\")\n",
    "else:\n",
    "    print(\"⚠️ Batch Size muy alto para RTX 4050, reduciendo...\")\n",
    "    batch_size = 2\n",
    "\n",
    "if not cache:\n",
    "    print(\"✅ Caché GPU deshabilitado (correcto para 6GB VRAM)\")\n",
    "else:\n",
    "    print(\"⚠️ Corrigiendo caché GPU...\")\n",
    "    cache = False\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 🚀 EJECUTAR ENTRENAMIENTO con configuración single-GPU optimizada\n",
    "training_log = click_train(\n",
    "    model_name,      # Nombre del modelo\n",
    "    sample_rate,     # '32k' - frecuencia de muestreo optimizada\n",
    "    True,           # if_f0_3 - usar información de pitch/tono (siempre True para calidad)\n",
    "    0,              # spk_id5 - ID del hablante (0 para single-speaker)\n",
    "    save_frequency, # Guardar checkpoint cada X epochs (25 recomendado)\n",
    "    epochs,         # Número total de epochs (300 balanceado)\n",
    "    batch_size,     # Tamaño del lote optimizado para RTX 4050\n",
    "    True,           # if_save_latest13 - siempre guardar modelo más reciente\n",
    "    G_file,         # Generador preentrenado (v2 estándar)\n",
    "    D_file,         # Discriminador preentrenado (v2 estándar)\n",
    "    gpu_config,     # \"0\" - configuración single-GPU forzada\n",
    "    cache,          # False - sin caché para ahorrar VRAM\n",
    "    True,           # if_save_every_weights18 - guardar todos los checkpoints\n",
    "    'v2',           # version19 - usar modelo v2 (mejor calidad)\n",
    ")\n",
    "\n",
    "# Mostrar resultado final del entrenamiento\n",
    "print(\"\\n🎉 RESULTADO DEL ENTRENAMIENTO:\")\n",
    "print(\"=\" * 70)\n",
    "print(training_log)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# INFORMACIÓN POST-ENTRENAMIENTO\n",
    "print(\"\\n📋 INFORMACIÓN POST-ENTRENAMIENTO:\")\n",
    "print(\"📁 Archivos generados en: ./logs/{}/\".format(model_name))\n",
    "print(\"📊 Monitoreo TensorBoard: http://localhost:8888\")\n",
    "print(\"💾 Checkpoints guardados cada {} epochs\".format(save_frequency))\n",
    "print(\"🎯 Modelo final: ./logs/{}/G_{}.pth\".format(model_name, epochs))\n",
    "print(\"🎵 Para inferencia, usa el archivo .pth generado\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 CONFIGURANDO TENSORBOARD...\n",
      "✅ TensorBoard disponible\n",
      "📊 Directorio de logs: ./RVC/logs/My-Voice\n",
      "⚠️ Directorio de logs no existe aún - se creará durante el entrenamiento\n",
      "📋 Para iniciar TensorBoard manualmente:\n",
      "1. Ejecuta en terminal: tensorboard --logdir=./RVC/logs --port=8888\n",
      "2. O ejecuta la siguiente celda que contiene los comandos mágicos\n",
      "3. Abre http://localhost:8888 en tu navegador\n",
      "✅ TensorBoard configurado - listo para entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CONFIGURACIÓN TENSORBOARD CORREGIDA\n",
    "# Los comandos mágicos %load_ext y %tensorboard DEBEN ejecutarse en celdas separadas del notebook\n",
    "\n",
    "print(\"🔧 CONFIGURANDO TENSORBOARD...\")\n",
    "\n",
    "# Verificar si TensorBoard está disponible\n",
    "try:\n",
    "    import tensorboard\n",
    "    print(\"✅ TensorBoard disponible\")\n",
    "except ImportError:\n",
    "    print(\"❌ TensorBoard no instalado, instalando...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"tensorboard\"])\n",
    "    import tensorboard\n",
    "    print(\"✅ TensorBoard instalado exitosamente\")\n",
    "\n",
    "# Configurar directorio de logs para TensorBoard\n",
    "tensorboard_logdir = f\"./RVC/logs/{model_name}\"\n",
    "print(f\"📊 Directorio de logs: {tensorboard_logdir}\")\n",
    "\n",
    "# Verificar que existe el directorio de logs\n",
    "if os.path.exists(tensorboard_logdir):\n",
    "    print(\"✅ Directorio de logs encontrado\")\n",
    "else:\n",
    "    print(\"⚠️ Directorio de logs no existe aún - se creará durante el entrenamiento\")\n",
    "\n",
    "print(\"📋 Para iniciar TensorBoard manualmente:\")\n",
    "print(\"1. Ejecuta en terminal: tensorboard --logdir=./RVC/logs --port=8888\")\n",
    "print(\"2. O ejecuta la siguiente celda que contiene los comandos mágicos\")\n",
    "print(\"3. Abre http://localhost:8888 en tu navegador\")\n",
    "print(\"✅ TensorBoard configurado - listo para entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1daf3bbc71656237\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1daf3bbc71656237\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8888;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TensorBoard iniciado en: http://localhost:8888\n",
      "🔥 Abre esa URL en tu navegador para monitorear el entrenamiento\n"
     ]
    }
   ],
   "source": [
    "# 📊 INICIAR TENSORBOARD (Comandos mágicos en celda separada)\n",
    "# EJECUTA ESTA CELDA ANTES DEL ENTRENAMIENTO\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./RVC/logs --port 8888\n",
    "\n",
    "print(\"✅ TensorBoard iniciado en: http://localhost:8888\")\n",
    "print(\"🔥 Abre esa URL en tu navegador para monitorear el entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INICIANDO ENTRENAMIENTO RVC - CONFIGURACIÓN SINGLE-GPU RTX 4050\n",
      "======================================================================\n",
      "📁 Modelo: My-Voice\n",
      "🎵 Sample Rate: 32k\n",
      "🔢 Epochs: 300\n",
      "📦 Batch Size: 1\n",
      "🎛️ F0: Activado\n",
      "💾 Cache GPU: Desactivado\n",
      "📊 TensorBoard: Activado\n",
      "======================================================================\n",
      "🐍 Python ejecutable: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\Scripts\\python.exe\n",
      "🗂️ Python version: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "📦 Python path: c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\n",
      "📂 Directorio actual: C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\n",
      "✅ Directorio RVC confirmado - todos los elementos necesarios presentes\n",
      "✅ Script de entrenamiento modificado correctamente para single-GPU\n",
      "✅ PyTorch disponible: 2.4.1+cu121\n",
      "✅ CUDA disponible: 12.1\n",
      "✅ Ejecutando desde directorio RVC: C:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\RVC\n",
      "🎯 Comando de entrenamiento:\n",
      "c:\\Users\\jose_\\Documents\\samsung_ic\\datasets\\innobrand_proyect\\.venv\\Scripts\\python.exe infer/modules/train/train.py -e My-Voice -sr 32k -f0 1 -bs 1 -te 300 -se 25 -pg ./assets/pretrained_v2/f0G32k.pth -pd ./assets/pretrained_v2/f0D32k.pth -l 0 -c 0 -sw 1 -v v2\n",
      "🔥 INICIANDO ENTRENAMIENTO...\n",
      "📊 Monitorea el progreso en TensorBoard: http://localhost:8888\n",
      "⏱️ El entrenamiento puede tomar varias horas dependiendo del dataset y epochs\n",
      "🔄 Ejecutando con variables de entorno configuradas para single-GPU...\n",
      "❌ ERROR EN EL ENTRENAMIENTO:\n",
      "📥 Return code: 1\n",
      "\n",
      "📤 STDOUT:\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ SINGLE-GPU DETECTED: Running direct training (no multiprocessing)\n",
      "   INFO:My-Voice:ðŸ”§ SINGLE-GPU TRAINING STARTED\n",
      "   INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': './assets/pretrained_v2/f0G32k.pth', 'pretrainD': './assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 0, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "   DEBUG:infer.lib.infer_pack.models:gin_channels: 256, self.spk_embed_dim: 109\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0G32k.pth\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0D32k.pth\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   INFO:My-Voice:Train Epoch: 1 [0/333 (0%)]\tLoss_disc: 3.346714\tLoss_gen: 3.196678\tLoss_fm: 18.669750\tLoss_mel: 29.484741\tLoss_kl: 14.747654\tLR: 0.000100\t[2025-07-16 22:31:20] | (0:00:03.902409)\n",
      "\n",
      "🚨 STDERR:\n",
      "   Traceback (most recent call last):\n",
      "     File \"infer/modules/train/train.py\", line 1142, in <module>\n",
      "       main()\n",
      "     File \"infer/modules/train/train.py\", line 126, in main\n",
      "       run_single_gpu(0, hps, logger)\n",
      "     File \"infer/modules/train/train.py\", line 270, in run_single_gpu\n",
      "       train_and_evaluate_single_gpu(\n",
      "     File \"infer/modules/train/train.py\", line 544, in train_and_evaluate_single_gpu\n",
      "       if global_step % hps.train.eval_interval == 0:\n",
      "   AttributeError: 'HParams' object has no attribute 'eval_interval'\n",
      "🏁 Proceso de entrenamiento finalizado\n",
      "❌ ERROR EN EL ENTRENAMIENTO:\n",
      "📥 Return code: 1\n",
      "\n",
      "📤 STDOUT:\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ SINGLE-GPU DETECTED: Running direct training (no multiprocessing)\n",
      "   INFO:My-Voice:ðŸ”§ SINGLE-GPU TRAINING STARTED\n",
      "   INFO:My-Voice:{'data': {'filter_length': 1024, 'hop_length': 320, 'max_wav_value': 32768.0, 'mel_fmax': None, 'mel_fmin': 0.0, 'n_mel_channels': 80, 'sampling_rate': 32000, 'win_length': 1024, 'training_files': './logs\\\\My-Voice/filelist.txt'}, 'model': {'filter_channels': 768, 'gin_channels': 256, 'hidden_channels': 192, 'inter_channels': 192, 'kernel_size': 3, 'n_heads': 2, 'n_layers': 6, 'p_dropout': 0, 'resblock': '1', 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'resblock_kernel_sizes': [3, 7, 11], 'spk_embed_dim': 109, 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [20, 16, 4, 4], 'upsample_rates': [10, 8, 2, 2], 'use_spectral_norm': False}, 'train': {'batch_size': 1, 'betas': [0.8, 0.99], 'c_kl': 1.0, 'c_mel': 45, 'epochs': 20000, 'eps': 1e-09, 'fp16_run': True, 'init_lr_ratio': 1, 'learning_rate': 0.0001, 'log_interval': 200, 'lr_decay': 0.999875, 'seed': 1234, 'segment_size': 12800, 'warmup_epochs': 0}, 'model_dir': './logs\\\\My-Voice', 'experiment_dir': './logs\\\\My-Voice', 'save_every_epoch': 25, 'name': 'My-Voice', 'total_epoch': 300, 'pretrainG': './assets/pretrained_v2/f0G32k.pth', 'pretrainD': './assets/pretrained_v2/f0D32k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '32k', 'if_f0': 1, 'if_latest': 0, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "   DEBUG:infer.lib.infer_pack.models:gin_channels: 256, self.spk_embed_dim: 109\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0G32k.pth\n",
      "   INFO:My-Voice:loaded pretrained ./assets/pretrained_v2/f0D32k.pth\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   ðŸ”§ PARCHE SINGLE-GPU APLICADO - RTX 4050 MODE\n",
      "   INFO:My-Voice:Train Epoch: 1 [0/333 (0%)]\tLoss_disc: 3.346714\tLoss_gen: 3.196678\tLoss_fm: 18.669750\tLoss_mel: 29.484741\tLoss_kl: 14.747654\tLR: 0.000100\t[2025-07-16 22:31:20] | (0:00:03.902409)\n",
      "\n",
      "🚨 STDERR:\n",
      "   Traceback (most recent call last):\n",
      "     File \"infer/modules/train/train.py\", line 1142, in <module>\n",
      "       main()\n",
      "     File \"infer/modules/train/train.py\", line 126, in main\n",
      "       run_single_gpu(0, hps, logger)\n",
      "     File \"infer/modules/train/train.py\", line 270, in run_single_gpu\n",
      "       train_and_evaluate_single_gpu(\n",
      "     File \"infer/modules/train/train.py\", line 544, in train_and_evaluate_single_gpu\n",
      "       if global_step % hps.train.eval_interval == 0:\n",
      "   AttributeError: 'HParams' object has no attribute 'eval_interval'\n",
      "🏁 Proceso de entrenamiento finalizado\n"
     ]
    }
   ],
   "source": [
    "# 🎯 ENTRENAR MODELO RVC CON TODAS LAS CORRECCIONES APLICADAS\n",
    "# ========================================================================\n",
    "# ✅ CORRECCIONES IMPLEMENTADAS:\n",
    "# 1. Single-GPU training sin distributed/multiprocessing (elimina error libuv)\n",
    "# 2. TensorBoard programático sin comandos mágicos problemáticos\n",
    "# 3. Configuración optimizada para RTX 4050 laptop\n",
    "# 4. Rutas simplificadas - ya estamos en el directorio RVC\n",
    "# 5. Ambiente Python correcto - usando sys.executable del notebook\n",
    "# 6. Manejo de eval_interval faltante en configuración HParams\n",
    "# ========================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Definir variables faltantes usando los valores de variables del kernel\n",
    "final_batch_size = globals().get('batch_size', 2)\n",
    "final_cache = globals().get('cache', False)\n",
    "use_f0 = True  # Para entrenamiento de voz humana siempre usar F0\n",
    "\n",
    "print(\"🚀 INICIANDO ENTRENAMIENTO RVC - CONFIGURACIÓN SINGLE-GPU RTX 4050\")\n",
    "print(\"=\"*70)\n",
    "print(f\"📁 Modelo: {model_name}\")\n",
    "print(f\"🎵 Sample Rate: {sample_rate}\")\n",
    "print(f\"🔢 Epochs: {epochs}\")\n",
    "print(f\"📦 Batch Size: {final_batch_size}\")\n",
    "print(f\"🎛️ F0: {'Activado' if use_f0 else 'Desactivado'}\")\n",
    "print(f\"💾 Cache GPU: {'Activado' if final_cache else 'Desactivado'}\")\n",
    "print(f\"📊 TensorBoard: {'Activado' if open_tensorboard else 'Desactivado'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verificar ambiente Python\n",
    "python_executable = sys.executable\n",
    "print(f\"🐍 Python ejecutable: {python_executable}\")\n",
    "print(f\"🗂️ Python version: {sys.version}\")\n",
    "print(f\"📦 Python path: {sys.prefix}\")\n",
    "\n",
    "# Verificar directorio actual - debemos estar en RVC\n",
    "current_dir = os.getcwd()\n",
    "print(f\"📂 Directorio actual: {current_dir}\")\n",
    "\n",
    "# Verificar que estamos en el directorio RVC correcto\n",
    "required_items = [\"infer\", \"assets\", \"logs\"]\n",
    "missing_items = [item for item in required_items if not os.path.exists(item)]\n",
    "\n",
    "if missing_items:\n",
    "    print(f\"❌ Faltan elementos RVC: {missing_items}\")\n",
    "    print(\"📁 Contenido del directorio actual:\")\n",
    "    for item in os.listdir(current_dir):\n",
    "        print(f\"   • {item}\")\n",
    "    raise FileNotFoundError(f\"Directorio RVC incompleto. Faltan: {missing_items}\")\n",
    "else:\n",
    "    print(\"✅ Directorio RVC confirmado - todos los elementos necesarios presentes\")\n",
    "\n",
    "# Verificar script de entrenamiento modificado\n",
    "train_script_path = \"infer/modules/train/train.py\"\n",
    "if os.path.exists(train_script_path):\n",
    "    with open(train_script_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        if \"🔧 PARCHE SINGLE-GPU APLICADO\" in content and \"run_single_gpu\" in content:\n",
    "            print(\"✅ Script de entrenamiento modificado correctamente para single-GPU\")\n",
    "            \n",
    "            # Verificar corrección específica de eval_interval\n",
    "            if \"getattr(hps.train, 'eval_interval'\" in content:\n",
    "                print(\"✅ Corrección eval_interval aplicada correctamente\")\n",
    "            else:\n",
    "                print(\"⚠️ Corrección eval_interval faltante - podría causar errores\")\n",
    "        else:\n",
    "            print(\"⚠️ Script de entrenamiento no modificado - usando versión original\")\n",
    "else:\n",
    "    print(f\"❌ Script de entrenamiento no encontrado: {train_script_path}\")\n",
    "\n",
    "# Verificar disponibilidad de dependencias en el ambiente actual\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✅ PyTorch disponible: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✅ CUDA disponible: {torch.version.cuda}\")\n",
    "        \n",
    "        # Información detallada de GPU para debugging\n",
    "        device = torch.cuda.current_device()\n",
    "        gpu_name = torch.cuda.get_device_name(device)\n",
    "        memory_total = torch.cuda.get_device_properties(device).total_memory / 1024**3\n",
    "        print(f\"✅ GPU activa: {gpu_name} ({memory_total:.1f}GB)\")\n",
    "    else:\n",
    "        print(\"⚠️ CUDA no disponible en este ambiente\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importando PyTorch: {e}\")\n",
    "\n",
    "# Verificar dataset y archivos de entrenamiento\n",
    "model_logs_path = f\"./logs/{model_name}\"\n",
    "if os.path.exists(model_logs_path):\n",
    "    filelist_path = f\"{model_logs_path}/filelist.txt\"\n",
    "    if os.path.exists(filelist_path):\n",
    "        with open(filelist_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"✅ Filelist encontrado: {len(lines)} archivos de entrenamiento\")\n",
    "    else:\n",
    "        print(\"⚠️ Filelist no encontrado - podría necesitar regeneración\")\n",
    "    \n",
    "    # Verificar directorios de datos necesarios\n",
    "    data_dirs = [\"0_gt_wavs\", \"2a_f0\", \"2b-f0nsf\", \"3_feature768\"]\n",
    "    for data_dir in data_dirs:\n",
    "        dir_path = f\"{model_logs_path}/{data_dir}\"\n",
    "        if os.path.exists(dir_path):\n",
    "            file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
    "            print(f\"✅ {data_dir}: {file_count} archivos\")\n",
    "        else:\n",
    "            print(f\"❌ {data_dir}: directorio faltante\")\n",
    "else:\n",
    "    print(f\"❌ Directorio del modelo no encontrado: {model_logs_path}\")\n",
    "\n",
    "# Ejecutar entrenamiento directamente desde el directorio RVC actual\n",
    "try:\n",
    "    print(f\"✅ Ejecutando desde directorio RVC: {os.getcwd()}\")\n",
    "    \n",
    "    # Configurar variables de entorno para single-GPU\n",
    "    env = os.environ.copy()\n",
    "    env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    env[\"WORLD_SIZE\"] = \"1\"\n",
    "    env[\"RANK\"] = \"0\"\n",
    "    env[\"LOCAL_RANK\"] = \"0\"\n",
    "    \n",
    "    # Limpiar caché CUDA antes de iniciar\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"✅ Caché CUDA limpiado antes del entrenamiento\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Construir comando de entrenamiento con el Python correcto del ambiente\n",
    "    train_command = [\n",
    "        python_executable,  # Usar el mismo Python del notebook\n",
    "        \"infer/modules/train/train.py\",\n",
    "        \"-e\", model_name,\n",
    "        \"-sr\", sample_rate,\n",
    "        \"-f0\", \"1\" if use_f0 else \"0\",\n",
    "        \"-bs\", str(final_batch_size),\n",
    "        \"-te\", str(epochs),\n",
    "        \"-se\", str(save_frequency),\n",
    "        \"-pg\", \"./assets/pretrained_v2/f0G32k.pth\",\n",
    "        \"-pd\", \"./assets/pretrained_v2/f0D32k.pth\",\n",
    "        \"-l\", \"1\" if final_cache else \"0\",\n",
    "        \"-c\", \"0\",  # single-GPU\n",
    "        \"-sw\", \"1\",  # save weights\n",
    "        \"-v\", \"v2\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"🎯 Comando de entrenamiento:\")\n",
    "    print(\" \".join(train_command))\n",
    "    print(\"🔥 INICIANDO ENTRENAMIENTO...\")\n",
    "    print(\"📊 Monitorea el progreso en TensorBoard: http://localhost:8888\")\n",
    "    print(\"⏱️ El entrenamiento puede tomar varias horas dependiendo del dataset y epochs\")\n",
    "    print(\"🔄 Ejecutando con variables de entorno configuradas para single-GPU...\")\n",
    "    \n",
    "    # Ejecutar entrenamiento con el ambiente correcto\n",
    "    result = subprocess.run(\n",
    "        train_command, \n",
    "        capture_output=True, \n",
    "        text=True, \n",
    "        env=env,  # Pasar variables de entorno configuradas\n",
    "        cwd=current_dir  # Asegurar directorio de trabajo correcto\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ ENTRENAMIENTO COMPLETADO CON ÉXITO!\")\n",
    "        print(\"📁 Modelos guardados en: ./logs/\")\n",
    "        print(\"🎵 Listo para usar en inferencia!\")\n",
    "        \n",
    "        # Mostrar algunas líneas finales del log si está disponible\n",
    "        if result.stdout:\n",
    "            print(\"\\n📋 ÚLTIMAS LÍNEAS DEL LOG:\")\n",
    "            stdout_lines = result.stdout.strip().split('\\n')\n",
    "            for line in stdout_lines[-10:]:  # Últimas 10 líneas\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(\"❌ ERROR EN EL ENTRENAMIENTO:\")\n",
    "        print(f\"📥 Return code: {result.returncode}\")\n",
    "        \n",
    "        if result.stdout:\n",
    "            print(\"\\n📤 STDOUT:\")\n",
    "            stdout_lines = result.stdout.strip().split('\\n')\n",
    "            for line in stdout_lines[-25:]:  # Últimas 25 líneas del stdout\n",
    "                print(f\"   {line}\")\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"\\n🚨 STDERR:\")\n",
    "            stderr_lines = result.stderr.strip().split('\\n')\n",
    "            for line in stderr_lines[-15:]:  # Últimas 15 líneas del stderr\n",
    "                print(f\"   {line}\")\n",
    "        \n",
    "        # Análisis específico de errores conocidos\n",
    "        full_output = (result.stdout or \"\") + (result.stderr or \"\")\n",
    "        \n",
    "        if \"use_libuv was requested but PyTorch was build without libuv support\" in full_output:\n",
    "            print(\"\\n🔧 ERROR DETECTADO: libuv\")\n",
    "            print(\"💡 SOLUCIÓN: Verificar que el script train.py esté modificado para single-GPU\")\n",
    "        \n",
    "        if \"No module named\" in full_output:\n",
    "            print(\"\\n🔧 ERROR DETECTADO: Módulo faltante\")\n",
    "            print(\"💡 SOLUCIÓN: Instalar dependencias en el ambiente actual\")\n",
    "        \n",
    "        if \"CUDA\" in full_output and \"not available\" in full_output:\n",
    "            print(\"\\n🔧 ERROR DETECTADO: CUDA no disponible\")\n",
    "            print(\"💡 SOLUCIÓN: Verificar instalación de PyTorch con CUDA\")\n",
    "            \n",
    "        if \"AttributeError\" in full_output and \"eval_interval\" in full_output:\n",
    "            print(\"\\n🔧 ERROR DETECTADO: eval_interval faltante\")\n",
    "            print(\"💡 SOLUCIÓN: Script train.py necesita corrección adicional\")\n",
    "            \n",
    "        if \"FileNotFoundError\" in full_output:\n",
    "            print(\"\\n🔧 ERROR DETECTADO: Archivo no encontrado\")\n",
    "            print(\"💡 SOLUCIÓN: Verificar que todos los archivos de preprocesamiento estén presentes\")\n",
    "            \n",
    "        if \"RuntimeError\" in full_output and (\"CUDA\" in full_output or \"GPU\" in full_output):\n",
    "            print(\"\\n🔧 ERROR DETECTADO: Error de GPU/CUDA\")\n",
    "            print(\"💡 SOLUCIÓN: Verificar memoria GPU disponible o reducir batch_size\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"⏹️ Entrenamiento interrumpido por el usuario\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error durante el entrenamiento: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"🏁 Proceso de entrenamiento finalizado\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
